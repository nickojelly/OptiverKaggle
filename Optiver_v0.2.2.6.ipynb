{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch_classes\n",
    "from model_saver import model_saver_wandb as model_saver\n",
    "import training_testing\n",
    "from itertools import combinations\n",
    "import gc\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\";\n",
    "median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True)\n",
    "    \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + train['ask_size']\n",
    "#     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "#     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0) \n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "    df['ask_x_size'] = df.eval('ask_size*ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size*bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        \n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        # 'date_id', \n",
    "        'reference_price_far_price_imb',\n",
    "        'reference_price_minus_near_price',\n",
    "        'reference_price_near_price_imb',\n",
    "        'far_price_near_price_imb',\n",
    "        'far_price_ask_price_imb',\n",
    "        'far_price_bid_price_imb',\n",
    "        'far_price_minus_wap',\n",
    "        'std_size',\n",
    "        'bid_size_over_ask_size',\n",
    "        'ask_price_bid_price_imb',\n",
    "        'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target'].values\n",
    "X = feat_eng(train)\n",
    "prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X['pca_prices'] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:13<01:50,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=438,for stock_id=19, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [01:26<01:09,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=328,for stock_id=101, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [01:52<00:44,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=35,for stock_id=131, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [02:23<00:27,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=388,for stock_id=158, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 385, Length of test 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 8176.61it/s]\n",
      "100%|██████████| 95/95 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(torch_classes)\n",
    "trading_data = torch_classes.TradingData(X)\n",
    "hidden_size = 64\n",
    "trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(torch_classes)\n",
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_classes.GRUNetV2(12,64,num_layers=2).to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNetV2(\n",
       "  (gru): GRU(12, 64, num_layers=2, dropout=0.3)\n",
       "  (relu0): ReLU()\n",
       "  (batch_norm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): LayerNorm((12800,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc0): Linear(in_features=12800, out_features=1024, bias=True)\n",
       "  (rl1): ReLU()\n",
       "  (drop1): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=640, bias=True)\n",
       "  (rl2): ReLU()\n",
       "  (drop2): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=640, out_features=200, bias=True)\n",
       "  (rl3): ReLU()\n",
       "  (drop3): Dropout(p=0.3, inplace=False)\n",
       "  (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(trading_df:torch_classes.TradingData, config:dict):\n",
    "    with wandb.init(project=\"Optviver\", config=config,save_code=True):\n",
    "        wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "        wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "        model = torch_classes.GRUNetV2(80,config['hidden_size'],num_layers=config['num_layers']).to('cuda:0')\n",
    "        config = wandb.config\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        print(model)\n",
    "        trading_df.reset_hidden(config['hidden_size'],num_layers=config['num_layers'])\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        \n",
    "        training_testing.train_model(trading_df,model,config,optimizer,criterion)\n",
    "\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {'learning_rate':0.0001, 'hidden_size':63, 'num_layers':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [trading_data.stocksDict[x] for x in trading_data.stock_batches[0]]\n",
    "X = trading_data.packed_val_x[0] \n",
    "Y = trading_data.packed_val_y[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_in = torch.stack([x.hidden for x in stocks]).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output,hidden = model(X,hidden_in,p1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch_classes.GRUNetV2(12,64)\n",
    "# model_loc = f\"C:/Users/Nick/Documents/GitHub/OptiverKaggle/models/tough-totem-105/tough-totem-105_160.pt\"\n",
    "# model_data = torch.load(model_loc,map_location=torch.device('cuda:0'))\n",
    "# print(model_data['model_state_dict'].keys())\n",
    "\n",
    "# print(model_data['model_state_dict'].keys())\n",
    "# del_keys = ['fc0.weight', 'fc0.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']\n",
    "# [model_data['model_state_dict'].pop(k) for k in del_keys]\n",
    "# model.load_state_dict(model_data['model_state_dict'], strict=False)\n",
    "# model = model.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\wandb\\run-20231010_110955-dtjvd699</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/Optviver/runs/dtjvd699' target=\"_blank\">dainty-aardvark-233</a></strong> to <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">https://wandb.ai/nickojelly/Optviver</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/Optviver/runs/dtjvd699' target=\"_blank\">https://wandb.ai/nickojelly/Optviver/runs/dtjvd699</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNetV2(\n",
      "  (gru): GRU(80, 63, num_layers=2, dropout=0.3)\n",
      "  (relu0): ReLU()\n",
      "  (batch_norm): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch_norm2): LayerNorm((12600,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc0): Linear(in_features=12600, out_features=1024, bias=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=640, out_features=200, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d4f08f9f8b4fa693f370a44080d738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_loss': tensor(1.2448, device='cuda:0'), 'epoch_l1_loss': tensor(1.3579, device='cuda:0'), 'epoch': 0}\n",
      "   stock  day  time    target      pred\n",
      "0      0    0     0 -3.029704 -0.035211\n",
      "1      1    0     0 -5.519986  0.032717\n",
      "2      2    0     0 -8.389950  0.005464\n",
      "3      3    0     0 -4.010201 -0.056723\n",
      "4      4    0     0 -7.349849 -0.019788\n",
      "5      5    0     0  6.779432 -0.004009\n",
      "6      6    0     0 -2.499819  0.018939\n",
      "7      7    0     0 -1.959801  0.006730\n",
      "8      8    0     0 -5.970001 -0.032274\n",
      "9      9    0     0  7.970333 -0.045781\n",
      "created path\n",
      "{'epoch_loss': tensor(1.2446, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 1}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 2}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 3}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 4}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 5}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 6}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 7}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 8}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 9}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 10}\n",
      "   stock  day  time    target      pred\n",
      "0      0    0     0 -3.029704 -0.044459\n",
      "1      1    0     0 -5.519986 -0.002761\n",
      "2      2    0     0 -8.389950 -0.075736\n",
      "3      3    0     0 -4.010201 -0.102698\n",
      "4      4    0     0 -7.349849 -0.354543\n",
      "5      5    0     0  6.779432 -0.018499\n",
      "6      6    0     0 -2.499819 -0.032025\n",
      "7      7    0     0 -1.959801  0.057413\n",
      "8      8    0     0 -5.970001 -0.133176\n",
      "9      9    0     0  7.970333 -0.419209\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 11}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 12}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 13}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 14}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 15}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 16}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 17}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 18}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 19}\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 20}\n",
      "   stock  day  time    target      pred\n",
      "0      0    0     0 -3.029704 -0.059876\n",
      "1      1    0     0 -5.519986 -0.093538\n",
      "2      2    0     0 -8.389950 -0.132357\n",
      "3      3    0     0 -4.010201 -0.133189\n",
      "4      4    0     0 -7.349849 -0.181474\n",
      "5      5    0     0  6.779432 -0.005055\n",
      "6      6    0     0 -2.499819  0.027115\n",
      "7      7    0     0 -1.959801  0.106464\n",
      "8      8    0     0 -5.970001 -0.081393\n",
      "9      9    0     0  7.970333 -0.134916\n",
      "{'epoch_loss': tensor(1.2445, device='cuda:0'), 'epoch_l1_loss': tensor(1.3578, device='cuda:0'), 'epoch': 21}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3577, device='cuda:0'), 'epoch': 22}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 23}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 24}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 25}\n",
      "{'epoch_loss': tensor(1.2444, device='cuda:0'), 'epoch_l1_loss': tensor(1.3576, device='cuda:0'), 'epoch': 26}\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline(trading_data, config_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden,targets = trading_data.fetch_daily_data(day=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden = [x.to('cpu') for x in stocks_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 63])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stocks_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 63 but got size 64 for tensor number 69 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.2.2.5.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.5.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mcat(stocks_hidden,dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 63 but got size 64 for tensor number 69 in the list."
     ]
    }
   ],
   "source": [
    "torch.cat(stocks_hidden,dim=0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
