{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import utils.public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import utils.torch_classes as torch_classes\n",
    "from utils.model_saver import model_saver_wandb as model_saver\n",
    "import utils.training_testing_double \n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "import importlib\n",
    "import gc\n",
    "from utils.constants import *\n",
    "# from utils.conts import lgbm_columns\n",
    "import time\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(torch_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ohe = torch_classes.GRUNetV5_a(input_size=23,hidden_size=64,num_layers=2,target_size=7,fc0_size=128)\n",
    "model_reg = torch_classes.GRUNetV5_b(input_size=23,hidden_size=64,num_layers=2,target_size=7,fc0_size=128)\n",
    "model_loc = f\"models/silver-plasma-493/silver-plasma-493_40.pt\"\n",
    "model_data = torch.load(model_loc,map_location=torch.device('cpu'))\n",
    "print(model_data.keys())\n",
    "print(model_data['model_state_dict_ohe'].keys())\n",
    "print(model_data['model_state_dict_reg'].keys())\n",
    "model_ohe.load_state_dict(model_data['model_state_dict_ohe'], strict=True)\n",
    "# model_reg.load_state_dict(model_data['model_state_dict_reg'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_feather('train.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(data=list(zip(range(0,201),weights)),columns=['stock_id','index_weight'])\n",
    "train = train.merge(weights_df,on='stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\"\n",
    "median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_data = torch_classes.TradingData()\n",
    "trading_data.fill_hidden_states_for_test(model_data['db_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True)\n",
    "    \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + train['ask_size']\n",
    "#     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "#     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0) \n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "    df['ask_x_size'] = df.eval('ask_size*ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size*bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        \n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        # 'date_id', \n",
    "        'reference_price_far_price_imb',\n",
    "        'reference_price_minus_near_price',\n",
    "        'reference_price_near_price_imb',\n",
    "        'far_price_near_price_imb',\n",
    "        'far_price_ask_price_imb',\n",
    "        'far_price_bid_price_imb',\n",
    "        'far_price_minus_wap',\n",
    "        'std_size',\n",
    "        'bid_size_over_ask_size',\n",
    "        'ask_price_bid_price_imb',\n",
    "        'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    # gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prev_race(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'initial_wap'] = df_g['wap_calc'].transform('first')\n",
    "    df[f'initial_bid_size'] = df_g['bid_size'].transform('first')\n",
    "    df[f'initial_ask_size'] = df_g['ask_size'].transform('first')\n",
    "    cols = [\"bid_price\", \"ask_price\", \"bid_size\", \"ask_size\", \"wap\"]\n",
    "    for i in cols:\n",
    "        df[f\"{i}_t10\"] = df_g[i].shift(1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap'] = df_g['wap_weighted'].transform('mean')\n",
    "    return(df)\n",
    "\n",
    "def generate_index_2(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap_init'] = df_g['index_wap'].transform('first')\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_eng(train):\n",
    "\n",
    "    train['wap_weighted'] = train['wap']*train['index_weight']\n",
    "    train_g = train.groupby(['stock_id','date_id'])\n",
    "    train = generate_prev_race(train,train_g)\n",
    "\n",
    "    train_g = train.groupby(['seconds_in_bucket','date_id'])\n",
    "    train = generate_index(train,train_g)\n",
    "\n",
    "\n",
    "    train['wap_move_to_init'] = train['wap_calc']/train['initial_wap']\n",
    "    train_g = train.groupby(['date_id'])\n",
    "    train = generate_index_2(train,train_g)\n",
    "\n",
    "    train['index_wap_move_to_init'] = train['index_wap']/train['index_wap_init']\n",
    "    targets = [\"wap\", \"bid_price\", \"ask_price\"]\n",
    "    for i in targets:\n",
    "        train[f\"{i}_prev_move\"] = (train[f\"{i}\"] - train[f\"{i}_t10\"]).fillna(0) * 10000\n",
    "\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"target\"].values\n",
    "X = feat_eng(train)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "print(prices)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "# prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X[\"pca_prices\"] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tgt = lgb.Booster(model_file=\"data/lgbm_model_new_t60_train_target.lgb\")\n",
    "lgbm_wap = lgb.Booster(model_file=\"data/lgbm_model_new_t60_train_wap.lgb\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward_pass(model_ohe:torch_classes.GRUNetV5_a,model_reg:torch_classes.GRUNetV5_b, new_x, hidden_in):\n",
    "    output_wap_ohe, hidden, relu, x_h = model_ohe(new_x, hidden_in)\n",
    "    output_wap = model_reg(output_wap_ohe.detach())\n",
    "    output_wap_ohe = output_wap_ohe.squeeze()\n",
    "    output_wap = output_wap.squeeze()\n",
    "    hidden = hidden.transpose(0, 1)\n",
    "\n",
    "    return output_wap_ohe, output_wap, hidden, x_h , relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preds(test, trading_data:torch_classes.TradingData,model_ohe:torch_classes.GRUNetV5_a,model_reg:torch_classes.GRUNetV5_b):\n",
    "\n",
    "\n",
    "\n",
    "    test['stats']  = pd.Series(test[stat_col_full].fillna(-1).values.tolist())\n",
    "    stock_ids = test.stock_id.unique().tolist()\n",
    "    stocks = [trading_data.stocksDict[x] for x in stock_ids]\n",
    "    hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1).squeeze()\n",
    "    \n",
    "    X = [torch.tensor(x) for x in test['stats'].tolist()]\n",
    "    \n",
    "    Xstacked = torch.tensor(test[stat_col_full].to_numpy()).unsqueeze(1)\n",
    "\n",
    "    print(f\"{Xstacked.shape=}\")\n",
    "    print(f\"{hidden.shape=},{Xstacked.shape=}\")\n",
    "    \n",
    "    \n",
    "    output_wap_ohe, output_wap, hidden, x_h , relu = model_forward_pass(model_ohe,model_reg, Xstacked, hidden)\n",
    "\n",
    "    # print(hidden.shape)\n",
    "    # hidden = hidden.transpose(0,1)\n",
    "    [setattr(obj, \"hidden\", val) for obj, val in zip(stocks, hidden)]\n",
    "    \n",
    "    output = output_wap.flatten().tolist()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preds(test, trading_data:torch_classes.TradingData, model_ohe:torch_classes.GRUNetV5_a,model_reg:torch_classes.GRUNetV5_b):\n",
    "    output = []\n",
    "    for i in range(len(test)):\n",
    "        # try:\n",
    "            row = test.iloc[[i]]\n",
    "            # print(row)\n",
    "            stats = row[stat_cols].fillna(-1).values.tolist()\n",
    "            stock_id = row['stock_id'].iloc[0] \n",
    "            stock = trading_data.stocksDict[stock_id]\n",
    "            hidden = stock.hidden.squeeze().unsqueeze(1)\n",
    "            \n",
    "            X = torch.tensor(stats)\n",
    "            print(f\"{X.shape=}\")\n",
    "            print(f\"{hidden.shape=}\")\n",
    "            Xstacked = X.unsqueeze(1)\n",
    "            print(f\"{Xstacked.shape=},{hidden.shape=}\")\n",
    "            output_wap_ohe, output_wap, hidden, x_h , relu = model_forward_pass(model_ohe,model_reg, Xstacked, hidden)\n",
    "            \n",
    "            stock.hidden = hidden\n",
    "            output.append(output_wap.item())\n",
    "        # except Exception as e:\n",
    "            # print(e)\n",
    "            # output.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "trading_data.fill_hidden_states_for_test(model_data['db_train'])\n",
    "\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    test_in = test[['stock_id','seconds_in_bucket','date_id']].copy()\n",
    "    if counter == 0:\n",
    "        print(test.head(3))\n",
    "        print(revealed_targets.head(3))\n",
    "        print(sample_prediction.head(3))\n",
    "        all_df = test\n",
    "    else:\n",
    "        # all_df = pd.concat([all_df,test])\n",
    "        pass\n",
    "    model_reg.eval()\n",
    "    model_ohe.eval()    \n",
    "    # test = all_df\n",
    "    print(counter)\n",
    "    test['wap_calc'] = (test['bid_price']*test['ask_size']+test['ask_price']*test['bid_size'])/(test['ask_size']+test['bid_size'])\n",
    "    test = test.merge(weights_df,on='stock_id')\n",
    "    test = feat_eng(test)\n",
    "    test['pca_prices'] = pca_prices.transform(test[prices].fillna(1).to_numpy())\n",
    "    if counter ==0:        \n",
    "        test = variable_eng(test)\n",
    "    else:\n",
    "        test = pd.concat([all_df,test])\n",
    "        test = variable_eng(test)\n",
    "    test = test.merge(test_in,on=['stock_id','seconds_in_bucket','date_id'],how='inner')\n",
    "    x = test[[c for c in test.columns if (\"target\" not in c) and (\"60\" not in c)]].drop(columns=[\"date_id\",\"stats\"])\n",
    "    lgbm_preds = lgbm_wap.predict(x[lgbm_columns])\n",
    "    test[\"lgbm_preds_wap\"] = lgbm_preds\n",
    "    lgbm_preds = lgbm_tgt.predict(x[lgbm_columns])\n",
    "    test[\"lgbm_preds_target\"] = lgbm_preds\n",
    "\n",
    "    preditcions = gen_preds(test,trading_data,model_ohe=model_ohe,model_reg=model_reg)\n",
    "    \n",
    "    sample_prediction['pred'] = preditcions\n",
    "    test_df = test\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
