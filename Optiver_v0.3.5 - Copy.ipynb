{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import (\n",
    "    pack_padded_sequence,\n",
    "    pack_sequence,\n",
    "    unpack_sequence,\n",
    "    unpad_sequence,\n",
    ")\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import utils.torch_classes\n",
    "from utils.model_saver import model_saver_wandb as model_saver\n",
    "import utils.training_testing\n",
    "import utils.training_testing_double\n",
    "from itertools import combinations\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=os.path.basename(__file__)\n"
     ]
    }
   ],
   "source": [
    "%env \"WANDB_NOTEBOOK_NAME\" os.path.basename(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\n",
    "        \"cuda:0\"\n",
    "    )  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_columns = [\n",
    "    \"stock_id\",\n",
    "    \"seconds_in_bucket\",\n",
    "    \"imbalance_size\",\n",
    "    \"imbalance_buy_sell_flag\",\n",
    "    \"reference_price\",\n",
    "    \"matched_size\",\n",
    "    \"far_price\",\n",
    "    \"near_price\",\n",
    "    \"bid_price\",\n",
    "    \"bid_size\",\n",
    "    \"ask_price\",\n",
    "    \"ask_size\",\n",
    "    \"wap\",\n",
    "    \"overall_medvol\",\n",
    "    \"first5min_medvol\",\n",
    "    \"last5min_medvol\",\n",
    "    \"bid_plus_ask_sizes\",\n",
    "    \"imbalance_ratio\",\n",
    "    \"imb_s1\",\n",
    "    \"imb_s2\",\n",
    "    \"ask_x_size\",\n",
    "    \"bid_x_size\",\n",
    "    \"ask_minus_bid\",\n",
    "    \"bid_price_over_ask_price\",\n",
    "    \"reference_price_minus_far_price\",\n",
    "    \"reference_price_times_far_price\",\n",
    "    \"reference_price_times_near_price\",\n",
    "    \"reference_price_minus_ask_price\",\n",
    "    \"reference_price_times_ask_price\",\n",
    "    \"reference_price_ask_price_imb\",\n",
    "    \"reference_price_minus_bid_price\",\n",
    "    \"reference_price_times_bid_price\",\n",
    "    \"reference_price_bid_price_imb\",\n",
    "    \"reference_price_minus_wap\",\n",
    "    \"reference_price_times_wap\",\n",
    "    \"reference_price_wap_imb\",\n",
    "    \"far_price_minus_near_price\",\n",
    "    \"far_price_times_near_price\",\n",
    "    \"far_price_minus_ask_price\",\n",
    "    \"far_price_times_ask_price\",\n",
    "    \"far_price_minus_bid_price\",\n",
    "    \"far_price_times_bid_price\",\n",
    "    \"far_price_times_wap\",\n",
    "    \"far_price_wap_imb\",\n",
    "    \"near_price_minus_ask_price\",\n",
    "    \"near_price_times_ask_price\",\n",
    "    \"near_price_ask_price_imb\",\n",
    "    \"near_price_minus_bid_price\",\n",
    "    \"near_price_times_bid_price\",\n",
    "    \"near_price_bid_price_imb\",\n",
    "    \"near_price_minus_wap\",\n",
    "    \"near_price_wap_imb\",\n",
    "    \"ask_price_minus_bid_price\",\n",
    "    \"ask_price_times_bid_price\",\n",
    "    \"ask_price_minus_wap\",\n",
    "    \"ask_price_times_wap\",\n",
    "    \"ask_price_wap_imb\",\n",
    "    \"bid_price_minus_wap\",\n",
    "    \"bid_price_times_wap\",\n",
    "    \"bid_price_wap_imb\",\n",
    "    \"reference_price_far_price_near_price_imb2\",\n",
    "    \"reference_price_far_price_ask_price_imb2\",\n",
    "    \"reference_price_far_price_bid_price_imb2\",\n",
    "    \"reference_price_far_price_wap_imb2\",\n",
    "    \"reference_price_near_price_ask_price_imb2\",\n",
    "    \"reference_price_near_price_bid_price_imb2\",\n",
    "    \"reference_price_near_price_wap_imb2\",\n",
    "    \"reference_price_ask_price_bid_price_imb2\",\n",
    "    \"reference_price_ask_price_wap_imb2\",\n",
    "    \"reference_price_bid_price_wap_imb2\",\n",
    "    \"far_price_near_price_ask_price_imb2\",\n",
    "    \"far_price_near_price_bid_price_imb2\",\n",
    "    \"far_price_near_price_wap_imb2\",\n",
    "    \"far_price_ask_price_bid_price_imb2\",\n",
    "    \"far_price_ask_price_wap_imb2\",\n",
    "    \"far_price_bid_price_wap_imb2\",\n",
    "    \"near_price_ask_price_bid_price_imb2\",\n",
    "    \"near_price_ask_price_wap_imb2\",\n",
    "    \"near_price_bid_price_wap_imb2\",\n",
    "    \"ask_price_bid_price_wap_imb2\",\n",
    "    \"pca_prices\",\n",
    "]\n",
    "\n",
    "weights = [\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.02,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.02,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.02,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.001,\n",
    "    0.04,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.008,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.02,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.02,\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.004,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.04,\n",
    "    0.002,\n",
    "    0.008,\n",
    "    0.002,\n",
    "    0.004,\n",
    "    0.001,\n",
    "    0.004,\n",
    "    0.006,\n",
    "    0.004,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(\n",
    "    data=list(zip(range(0, 201), weights)), columns=[\"stock_id\", \"index_weight\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(weights_df, on=\"stock_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"wap_calc\"] = (\n",
    "    train[\"bid_price\"] * train[\"ask_size\"] + train[\"ask_price\"] * train[\"bid_size\"]\n",
    ") / (train[\"ask_size\"] + train[\"bid_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'index_weight',\n",
       "       'wap_calc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prev_race(df_in, df_g, rolling_window=10, factor=\"\"):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f\"wap_t-60\"] = df_g[\"wap\"].shift(6)\n",
    "    df[f\"target_t-60\"] = df_g[\"target\"].shift(6)\n",
    "    df[f\"initial_wap\"] = df_g[\"wap_calc\"].transform(\"first\")\n",
    "    df[f\"initial_bid_size\"] = df_g[\"bid_size\"].transform(\"first\")\n",
    "    df[f\"initial_ask_size\"] = df_g[\"ask_size\"].transform(\"first\")\n",
    "    cols = [\"bid_price\", \"ask_price\", \"bid_size\", \"ask_size\", \"wap\"]\n",
    "    for i in cols:\n",
    "        df[f\"{i}_t-60\"] = df_g[i].shift(-6)\n",
    "    for i in cols:\n",
    "        df[f\"{i}_t10\"] = df_g[i].shift(1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(df_in, df_g, rolling_window=10, factor=\"\"):\n",
    "    df = df_in.copy()\n",
    "    df[f\"index_wap\"] = df_g[\"wap_weighted\"].transform(\"mean\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_index_2(df_in, df_g, rolling_window=10, factor=\"\"):\n",
    "    df = df_in.copy()\n",
    "    df[f\"index_wap_t-60\"] = df_g[\"index_wap\"].shift(6)\n",
    "    df[f\"index_wap_init\"] = df_g[\"index_wap\"].transform(\"first\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_index_3(df_in, df_g, rolling_window=10, factor=\"\"):\n",
    "    df = df_in.copy()\n",
    "    df[f\"index_wap_t-60\"] = df_g[\"index_wap_move_to_init\"].shift(6)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"wap_weighted\"] = train[\"wap\"] * train[\"index_weight\"]\n",
    "train_g = train.groupby([\"stock_id\", \"date_id\"])\n",
    "train = generate_prev_race(train, train_g)\n",
    "train[\"delta_wap\"] = train[\"wap\"] / train[\"wap_t-60\"]\n",
    "\n",
    "train_g = train.groupby([\"seconds_in_bucket\", \"date_id\"])\n",
    "train = generate_index(train, train_g)\n",
    "\n",
    "\n",
    "train[\"wap_move_to_init\"] = train[\"wap_calc\"] / train[\"initial_wap\"]\n",
    "train_g = train.groupby([\"date_id\"])\n",
    "train = generate_index_2(train, train_g)\n",
    "\n",
    "train[\"index_wap_move_to_init\"] = train[\"index_wap\"] / train[\"index_wap_init\"]\n",
    "train_g = train.groupby([\"date_id\"])\n",
    "train = generate_index_3(train, train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'index_weight',\n",
       "       'wap_calc', 'wap_weighted', 'wap_t-60', 'target_t-60', 'initial_wap',\n",
       "       'initial_bid_size', 'initial_ask_size', 'bid_price_t-60',\n",
       "       'ask_price_t-60', 'bid_size_t-60', 'ask_size_t-60', 'bid_price_t10',\n",
       "       'ask_price_t10', 'bid_size_t10', 'ask_size_t10', 'wap_t10', 'delta_wap',\n",
       "       'index_wap', 'wap_move_to_init', 'index_wap_t-60', 'index_wap_init',\n",
       "       'index_wap_move_to_init'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"target_calc\"] = (\n",
    "    -(\n",
    "        (train[\"wap_t-60\"] / train[\"wap\"])\n",
    "        - (train[\"index_wap_t-60\"] / train[\"index_wap_move_to_init\"])\n",
    "    )\n",
    "    * 10000\n",
    ")\n",
    "train[\"target_delta\"] = train[\"target_t-60\"] - train[\"target_calc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>ask_size_t10</th>\n",
       "      <th>wap_t10</th>\n",
       "      <th>delta_wap</th>\n",
       "      <th>index_wap</th>\n",
       "      <th>wap_move_to_init</th>\n",
       "      <th>index_wap_t-60</th>\n",
       "      <th>index_wap_init</th>\n",
       "      <th>index_wap_move_to_init</th>\n",
       "      <th>target_calc</th>\n",
       "      <th>target_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>23519.16</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>12131.60</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>1.000085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>46203.30</td>\n",
       "      <td>1.000085</td>\n",
       "      <td>1.000056</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>26610.45</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>1.000392</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>1.000435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>...</td>\n",
       "      <td>9897.22</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>1.000622</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>1.000517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000815</td>\n",
       "      <td>-1.930193</td>\n",
       "      <td>-1.099511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1264494.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15352380.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>10085.04</td>\n",
       "      <td>1.000517</td>\n",
       "      <td>1.000459</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>1.000422</td>\n",
       "      <td>1.000356</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>-0.279044</td>\n",
       "      <td>0.668858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1189832.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>15427043.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>17366.82</td>\n",
       "      <td>1.000421</td>\n",
       "      <td>1.000322</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000148</td>\n",
       "      <td>1.000525</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>4.376209</td>\n",
       "      <td>-0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1189272.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>15427602.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>61984.40</td>\n",
       "      <td>1.000148</td>\n",
       "      <td>1.000639</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000427</td>\n",
       "      <td>1.000547</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000345</td>\n",
       "      <td>8.409505</td>\n",
       "      <td>-2.959257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1249282.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>15427602.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>40433.54</td>\n",
       "      <td>1.000426</td>\n",
       "      <td>1.000666</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000261</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000264</td>\n",
       "      <td>10.363349</td>\n",
       "      <td>-7.193574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>1277280.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15399604.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>42572.16</td>\n",
       "      <td>1.000261</td>\n",
       "      <td>1.000548</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000042</td>\n",
       "      <td>1.000668</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>9.973232</td>\n",
       "      <td>-9.373609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1216057.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15460827.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>28375.36</td>\n",
       "      <td>1.000042</td>\n",
       "      <td>1.000226</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1.000815</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000217</td>\n",
       "      <td>8.245111</td>\n",
       "      <td>-8.445382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>1216057.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>15460827.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>68224.23</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>1.000207</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000147</td>\n",
       "      <td>9.028563</td>\n",
       "      <td>-6.618152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1104904.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>15571980.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>13999.50</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>1.000533</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.999827</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>8.134313</td>\n",
       "      <td>-8.524127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>25196.40</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>1.000556</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>1.000345</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>7.595631</td>\n",
       "      <td>-11.935445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>...</td>\n",
       "      <td>15769.39</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>1.000384</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.000264</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>8.417362</td>\n",
       "      <td>-10.467165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>...</td>\n",
       "      <td>186.58</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>1.000253</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>8.001506</td>\n",
       "      <td>-7.981241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1445736.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>15642349.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>...</td>\n",
       "      <td>28173.58</td>\n",
       "      <td>0.999494</td>\n",
       "      <td>1.000071</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>1.000217</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>5.236943</td>\n",
       "      <td>-2.946932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1771730.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>15642349.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>9330.00</td>\n",
       "      <td>0.999669</td>\n",
       "      <td>1.000446</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>1.000147</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>7.512073</td>\n",
       "      <td>-6.511907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0          0        0                  0      3180602.69   \n",
       "1          0        0                 10      1299772.70   \n",
       "2          0        0                 20      1299772.70   \n",
       "3          0        0                 30      1299772.70   \n",
       "4          0        0                 40      1218204.43   \n",
       "5          0        0                 50      1218204.43   \n",
       "6          0        0                 60      1218204.43   \n",
       "7          0        0                 70      1264494.89   \n",
       "8          0        0                 80      1189832.86   \n",
       "9          0        0                 90      1189272.89   \n",
       "10         0        0                100      1249282.50   \n",
       "11         0        0                110      1277280.77   \n",
       "12         0        0                120      1216057.90   \n",
       "13         0        0                130      1216057.90   \n",
       "14         0        0                140      1104904.79   \n",
       "15         0        0                150      1085679.32   \n",
       "16         0        0                160      1085679.32   \n",
       "17         0        0                170      1085679.32   \n",
       "18         0        0                180      1445736.98   \n",
       "19         0        0                190      1771730.09   \n",
       "\n",
       "    imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                         1         0.999812   13380276.64        NaN   \n",
       "1                         1         1.000026   15261106.63        NaN   \n",
       "2                         1         0.999919   15261106.63        NaN   \n",
       "3                         1         1.000133   15261106.63        NaN   \n",
       "4                         1         1.000455   15342674.90        NaN   \n",
       "5                         1         1.000455   15342674.90        NaN   \n",
       "6                         1         1.000562   15342674.90        NaN   \n",
       "7                         1         1.000455   15352380.96        NaN   \n",
       "8                         1         1.000241   15427043.00        NaN   \n",
       "9                         1         1.000562   15427602.97        NaN   \n",
       "10                        1         1.000348   15427602.97        NaN   \n",
       "11                        1         1.000133   15399604.70        NaN   \n",
       "12                        1         1.000133   15460827.57        NaN   \n",
       "13                        1         1.000026   15460827.57        NaN   \n",
       "14                        1         0.999919   15571980.68        NaN   \n",
       "15                        1         0.999812   15591206.15        NaN   \n",
       "16                        1         0.999598   15591206.15        NaN   \n",
       "17                        1         0.999598   15591206.15        NaN   \n",
       "18                        1         0.999705   15642349.64        NaN   \n",
       "19                        1         0.999812   15642349.64        NaN   \n",
       "\n",
       "    near_price  bid_price  ...  ask_size_t10   wap_t10  delta_wap  index_wap  \\\n",
       "0          NaN   0.999812  ...           NaN       NaN   0.999483   0.005031   \n",
       "1          NaN   0.999812  ...       8493.03  1.000000   0.999471   0.005033   \n",
       "2          NaN   0.999812  ...      23519.16  0.999892   0.999694   0.005034   \n",
       "3          NaN   1.000026  ...      12131.60  0.999842   0.999659   0.005034   \n",
       "4          NaN   1.000241  ...      46203.30  1.000085   1.000056   0.005035   \n",
       "5          NaN   1.000348  ...      26610.45  1.000317   1.000392   0.005035   \n",
       "6          NaN   1.000455  ...       9897.22  1.000434   1.000622   0.005036   \n",
       "7          NaN   1.000348  ...      10085.04  1.000517   1.000459   0.005036   \n",
       "8          NaN   1.000133  ...      17366.82  1.000421   1.000322   0.005033   \n",
       "9          NaN   1.000348  ...      61984.40  1.000148   1.000639   0.005033   \n",
       "10         NaN   1.000241  ...      40433.54  1.000426   1.000666   0.005033   \n",
       "11         NaN   1.000026  ...      42572.16  1.000261   1.000548   0.005033   \n",
       "12         NaN   0.999812  ...      28375.36  1.000042   1.000226   0.005033   \n",
       "13         NaN   0.999812  ...      68224.23  0.999895   1.000207   0.005032   \n",
       "14         NaN   0.999705  ...      13999.50  0.999962   1.000533   0.005032   \n",
       "15         NaN   0.999705  ...      25196.40  0.999826   1.000556   0.005032   \n",
       "16         NaN   0.999491  ...      15769.39  0.999787   1.000384   0.005030   \n",
       "17         NaN   0.999383  ...        186.58  0.999595   1.000253   0.005030   \n",
       "18         NaN   0.999598  ...      28173.58  0.999494   1.000071   0.005030   \n",
       "19         NaN   0.999705  ...       9330.00  0.999669   1.000446   0.005031   \n",
       "\n",
       "    wap_move_to_init  index_wap_t-60 index_wap_init  index_wap_move_to_init  \\\n",
       "0           1.000000             NaN       0.005031                1.000000   \n",
       "1           0.999892             NaN       0.005031                1.000356   \n",
       "2           0.999842             NaN       0.005031                1.000525   \n",
       "3           1.000085             NaN       0.005031                1.000547   \n",
       "4           1.000317             NaN       0.005031                1.000635   \n",
       "5           1.000435             NaN       0.005031                1.000668   \n",
       "6           1.000517        1.000000       0.005031                1.000815   \n",
       "7           1.000422        1.000356       0.005031                1.000843   \n",
       "8           1.000148        1.000525       0.005031                1.000409   \n",
       "9           1.000427        1.000547       0.005031                1.000345   \n",
       "10          1.000261        1.000635       0.005031                1.000264   \n",
       "11          1.000042        1.000668       0.005031                1.000218   \n",
       "12          0.999896        1.000815       0.005031                1.000217   \n",
       "13          0.999962        1.000843       0.005031                1.000147   \n",
       "14          0.999827        1.000409       0.005031                1.000129   \n",
       "15          0.999787        1.000345       0.005031                1.000142   \n",
       "16          0.999596        1.000264       0.005031                0.999807   \n",
       "17          0.999494        1.000218       0.005031                0.999672   \n",
       "18          0.999670        1.000217       0.005031                0.999764   \n",
       "19          0.999755        1.000147       0.005031                0.999842   \n",
       "\n",
       "    target_calc  target_delta  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  \n",
       "5           NaN           NaN  \n",
       "6     -1.930193     -1.099511  \n",
       "7     -0.279044      0.668858  \n",
       "8      4.376209     -0.156200  \n",
       "9      8.409505     -2.959257  \n",
       "10    10.363349     -7.193574  \n",
       "11     9.973232     -9.373609  \n",
       "12     8.245111     -8.445382  \n",
       "13     9.028563     -6.618152  \n",
       "14     8.134313     -8.524127  \n",
       "15     7.595631    -11.935445  \n",
       "16     8.417362    -10.467165  \n",
       "17     8.001506     -7.981241  \n",
       "18     5.236943     -2.946932  \n",
       "19     7.512073     -6.511907  \n",
       "\n",
       "[20 rows x 42 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stock_0 = train[train[\"stock_id\"] == 0].dropna(subset=\"bid_size_t-60\").copy()\n",
    "train_stock_0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seconds_in_bucket                0\n",
       "imbalance_size                 220\n",
       "imbalance_buy_sell_flag          0\n",
       "reference_price                220\n",
       "matched_size                   220\n",
       "far_price                  2894342\n",
       "near_price                 2857180\n",
       "bid_price                      220\n",
       "bid_size                         0\n",
       "ask_price                      220\n",
       "ask_size                         0\n",
       "wap                            220\n",
       "index_weight                     0\n",
       "wap_calc                       220\n",
       "initial_wap                    220\n",
       "wap_weighted                   220\n",
       "index_wap                        0\n",
       "index_wap_init                   0\n",
       "index_wap_move_to_init           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\n",
    "    [\n",
    "        \"seconds_in_bucket\",\n",
    "        \"imbalance_size\",\n",
    "        \"imbalance_buy_sell_flag\",\n",
    "        \"reference_price\",\n",
    "        \"matched_size\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"bid_price\",\n",
    "        \"bid_size\",\n",
    "        \"ask_price\",\n",
    "        \"ask_size\",\n",
    "        \"wap\",\n",
    "        \"index_weight\",\n",
    "        \"wap_calc\",\n",
    "        \"initial_wap\",\n",
    "        \"wap_weighted\",\n",
    "        \"index_wap\",\n",
    "        \"index_wap_init\",\n",
    "        \"index_wap_move_to_init\",\n",
    "    ]\n",
    "].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_stock_0.to_csv('train_with_new_vars_0stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\"\n",
    "median_vol = median_vol[[\"overall_medvol\", \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = (\n",
    "    train.groupby(\"stock_id\")[\"bid_size\"].median()\n",
    "    + train.groupby(\"stock_id\")[\"ask_size\"].median()\n",
    ")\n",
    "std_sizes = (\n",
    "    train.groupby(\"stock_id\")[\"bid_size\"].median()\n",
    "    + train.groupby(\"stock_id\")[\"ask_size\"].median()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"bid_price_target\"] = train[\"bid_price\"] - train[\"bid_price_t-60\"]\n",
    "train[\"bid_price_t-60\"] = train[\"bid_price_target\"] * 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"wap_target\"] = train[\"wap\"] - train[\"wap_t-60\"]\n",
    "train[\"wap_price_t-60\"] = train[\"wap_target\"] * 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"wap\", \"bid_price\", \"ask_price\"]\n",
    "for i in targets:\n",
    "    train[f\"{i}_prev_move\"] = (train[f\"{i}\"] - train[f\"{i}_t10\"]).fillna(0) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"ask_price_target\"] = train[\"ask_price\"] - train[\"ask_price_t-60\"]\n",
    "train[\"ask_price_t-60\"] = train[\"ask_price_target\"] * 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid_price_t-60</th>\n",
       "      <th>bid_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.43</td>\n",
       "      <td>0.999812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.36</td>\n",
       "      <td>0.999812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.21</td>\n",
       "      <td>0.999812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.22</td>\n",
       "      <td>1.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.22</td>\n",
       "      <td>1.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.43</td>\n",
       "      <td>1.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.36</td>\n",
       "      <td>1.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.28</td>\n",
       "      <td>1.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.43</td>\n",
       "      <td>1.000348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bid_price_t-60  bid_price\n",
       "0           -6.43   0.999812\n",
       "1           -5.36   0.999812\n",
       "2           -3.21   0.999812\n",
       "3           -3.22   1.000026\n",
       "4            0.00   1.000241\n",
       "5            3.22   1.000348\n",
       "6            6.43   1.000455\n",
       "7            5.36   1.000348\n",
       "8            4.28   1.000133\n",
       "9            6.43   1.000348"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"bid_price_t-60\", \"bid_price\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\"]]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how=\"left\", left_on=\"stock_id\", right_index=True)\n",
    "\n",
    "    df[\"bid_plus_ask_sizes\"] = df[\"bid_size\"] + train[\"ask_size\"]\n",
    "    #     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df[\"std_size\"] = df[\"stock_id\"].map(std_sizes.to_dict())\n",
    "    #     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0)\n",
    "    df[\"imbalance_ratio\"] = df[\"imbalance_size\"] / df[\"matched_size\"]\n",
    "\n",
    "    df[\"imb_s1\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"imb_s2\"] = df.eval(\n",
    "        \"(imbalance_size-matched_size)/(matched_size+imbalance_size)\"\n",
    "    )\n",
    "\n",
    "    df[\"ask_x_size\"] = df.eval(\"ask_size*ask_price\")\n",
    "    df[\"bid_x_size\"] = df.eval(\"bid_size*bid_price\")\n",
    "\n",
    "    df[\"ask_minus_bid\"] = df[\"ask_x_size\"] - df[\"bid_x_size\"]\n",
    "\n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "\n",
    "    prices = [\n",
    "        \"reference_price\",\n",
    "        \"far_price\",\n",
    "        \"near_price\",\n",
    "        \"ask_price\",\n",
    "        \"bid_price\",\n",
    "        \"wap\",\n",
    "    ]\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_minus_{c[1]}\"] = (df[f\"{c[0]}\"] - df[f\"{c[1]}\"]).astype(np.float32)\n",
    "        df[f\"{c[0]}_times_{c[1]}\"] = (df[f\"{c[0]}\"] * df[f\"{c[1]}\"]).astype(np.float32)\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]}-{c[1]})/({c[0]}+{c[1]})\")\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1) - min_ - max_\n",
    "\n",
    "        df[f\"{c[0]}_{c[1]}_{c[2]}_imb2\"] = (max_ - mid_) / (mid_ - min_)\n",
    "\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            # 'date_id',\n",
    "            \"reference_price_far_price_imb\",\n",
    "            \"reference_price_minus_near_price\",\n",
    "            \"reference_price_near_price_imb\",\n",
    "            \"far_price_near_price_imb\",\n",
    "            \"far_price_ask_price_imb\",\n",
    "            \"far_price_bid_price_imb\",\n",
    "            \"far_price_minus_wap\",\n",
    "            \"std_size\",\n",
    "            \"bid_size_over_ask_size\",\n",
    "            \"ask_price_bid_price_imb\",\n",
    "            \"near_price_times_wap\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reference_price', 'far_price', 'near_price', 'bid_price', 'ask_price', 'bid_price_t10', 'ask_price_t10', 'bid_price_prev_move', 'ask_price_prev_move', 'bid_price_over_ask_price', 'reference_price_minus_far_price', 'reference_price_times_far_price', 'reference_price_times_near_price', 'reference_price_minus_ask_price', 'reference_price_times_ask_price', 'reference_price_ask_price_imb', 'reference_price_minus_bid_price', 'reference_price_times_bid_price', 'reference_price_bid_price_imb', 'reference_price_minus_wap', 'reference_price_times_wap', 'reference_price_wap_imb', 'far_price_minus_near_price', 'far_price_times_near_price', 'far_price_minus_ask_price', 'far_price_times_ask_price', 'far_price_minus_bid_price', 'far_price_times_bid_price', 'far_price_times_wap', 'far_price_wap_imb', 'near_price_minus_ask_price', 'near_price_times_ask_price', 'near_price_ask_price_imb', 'near_price_minus_bid_price', 'near_price_times_bid_price', 'near_price_bid_price_imb', 'near_price_minus_wap', 'near_price_wap_imb', 'ask_price_minus_bid_price', 'ask_price_times_bid_price', 'ask_price_minus_wap', 'ask_price_times_wap', 'ask_price_wap_imb', 'bid_price_minus_wap', 'bid_price_times_wap', 'bid_price_wap_imb', 'reference_price_far_price_near_price_imb2', 'reference_price_far_price_ask_price_imb2', 'reference_price_far_price_bid_price_imb2', 'reference_price_far_price_wap_imb2', 'reference_price_near_price_ask_price_imb2', 'reference_price_near_price_bid_price_imb2', 'reference_price_near_price_wap_imb2', 'reference_price_ask_price_bid_price_imb2', 'reference_price_ask_price_wap_imb2', 'reference_price_bid_price_wap_imb2', 'far_price_near_price_ask_price_imb2', 'far_price_near_price_bid_price_imb2', 'far_price_near_price_wap_imb2', 'far_price_ask_price_bid_price_imb2', 'far_price_ask_price_wap_imb2', 'far_price_bid_price_wap_imb2', 'near_price_ask_price_bid_price_imb2', 'near_price_ask_price_wap_imb2', 'near_price_bid_price_wap_imb2', 'ask_price_bid_price_wap_imb2']\n"
     ]
    }
   ],
   "source": [
    "y = train[\"target\"].values\n",
    "X = feat_eng(train)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "# prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X[\"pca_prices\"] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                                 int64\n",
       "date_id                                  int64\n",
       "seconds_in_bucket                        int64\n",
       "imbalance_size                         float64\n",
       "imbalance_buy_sell_flag                  int64\n",
       "                                        ...   \n",
       "near_price_ask_price_bid_price_imb2    float64\n",
       "near_price_ask_price_wap_imb2          float64\n",
       "near_price_bid_price_wap_imb2          float64\n",
       "ask_price_bid_price_wap_imb2           float64\n",
       "pca_prices                             float64\n",
       "Length: 115, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.Booster(model_file=\"data/lgbm_model_new_t60.lgb\")\n",
    "X_train = X[[c for c in X.columns if (\"target\" not in c) and (\"60\" not in c)]].drop(\n",
    "    columns=[\"delta_wap\", \"date_id\"]\n",
    ")\n",
    "lgbm_preds = lgbm.predict(X_train)\n",
    "X[\"lgbm_preds\"] = lgbm_preds\n",
    "\n",
    "del pca_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.join(pca)\n",
    "X = X.dropna(subset=\"wap_t-60\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cols = [\n",
    "    \"seconds_in_bucket\",\n",
    "    \"imbalance_size\",\n",
    "    \"imbalance_buy_sell_flag\",\n",
    "    \"reference_price\",\n",
    "    \"matched_size\",\n",
    "    \"bid_price\",\n",
    "    \"bid_size\",\n",
    "    \"ask_price\",\n",
    "    \"ask_size\",\n",
    "    \"wap\",\n",
    "    \"index_weight\",\n",
    "    \"wap_calc\",\n",
    "    \"initial_wap\",\n",
    "    \"wap_weighted\",\n",
    "    \"index_wap\",\n",
    "    \"index_wap_init\",\n",
    "    \"index_wap_move_to_init\",\n",
    "    \"wap_prev_move\",\n",
    "    \"bid_price_prev_move\",\n",
    "    \"ask_price_prev_move\",\n",
    "    \"pca_prices\",\n",
    "    \"lgbm_preds\",\n",
    "]\n",
    "\n",
    "# stat_cols = ['seconds_in_bucket', 'imbalance_size',\n",
    "#        'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
    "#     #    'far_price', 'near_price',\n",
    "\n",
    "\n",
    "#        'bid_price', 'bid_size', 'ask_price', 'ask_size',\n",
    "#         'wap', 'index_weight','wap_calc','initial_wap','wap_weighted', 'index_wap', 'index_wap_init', 'index_wap_move_to_init',\n",
    "\n",
    "#         'wap_prev_move','bid_price_prev_move','ask_price_prev_move',\n",
    "\n",
    "#                  'overall_medvol', 'first5min_medvol',\n",
    "#        'last5min_medvol', 'bid_plus_ask_sizes', 'imbalance_ratio', 'imb_s1',\n",
    "#        'imb_s2', 'ask_x_size', 'bid_x_size', 'ask_minus_bid',\n",
    "#        'bid_price_over_ask_price', 'reference_price_minus_far_price',\n",
    "#        'reference_price_times_far_price', 'reference_price_times_near_price',\n",
    "#        'reference_price_minus_ask_price', 'reference_price_times_ask_price',\n",
    "#        'reference_price_ask_price_imb', 'reference_price_minus_bid_price',\n",
    "#        'reference_price_times_bid_price', 'reference_price_bid_price_imb',\n",
    "#        'reference_price_minus_wap', 'reference_price_times_wap',\n",
    "#        'reference_price_wap_imb', 'far_price_minus_near_price',\n",
    "#        'far_price_times_near_price', 'far_price_minus_ask_price',\n",
    "#        'far_price_times_ask_price', 'far_price_minus_bid_price',\n",
    "#        'far_price_times_bid_price', 'far_price_times_wap', 'far_price_wap_imb',\n",
    "#        'near_price_minus_ask_price', 'near_price_times_ask_price',\n",
    "#        'near_price_ask_price_imb', 'near_price_minus_bid_price',\n",
    "#        'near_price_times_bid_price', 'near_price_bid_price_imb',\n",
    "#        'near_price_minus_wap', 'near_price_wap_imb',\n",
    "#        'ask_price_minus_bid_price', 'ask_price_times_bid_price',\n",
    "#        'ask_price_minus_wap', 'ask_price_times_wap', 'ask_price_wap_imb',\n",
    "#        'bid_price_minus_wap', 'bid_price_times_wap', 'bid_price_wap_imb',\n",
    "#        'reference_price_far_price_near_price_imb2',\n",
    "#        'reference_price_far_price_ask_price_imb2',\n",
    "#        'reference_price_far_price_bid_price_imb2',\n",
    "#        'reference_price_far_price_wap_imb2',\n",
    "#        'reference_price_near_price_ask_price_imb2',\n",
    "#        'reference_price_near_price_bid_price_imb2',\n",
    "#        'reference_price_near_price_wap_imb2',\n",
    "#        'reference_price_ask_price_bid_price_imb2',\n",
    "#        'reference_price_ask_price_wap_imb2',\n",
    "#        'reference_price_bid_price_wap_imb2',\n",
    "#        'far_price_near_price_ask_price_imb2',\n",
    "#        'far_price_near_price_bid_price_imb2', 'far_price_near_price_wap_imb2',\n",
    "#        'far_price_ask_price_bid_price_imb2', 'far_price_ask_price_wap_imb2',\n",
    "#        'far_price_bid_price_wap_imb2', 'near_price_ask_price_bid_price_imb2',\n",
    "#        'near_price_ask_price_wap_imb2', 'near_price_bid_price_wap_imb2',\n",
    "#        'ask_price_bid_price_wap_imb2',\n",
    "\n",
    "\n",
    "#        'pca_prices', 'lgbm_preds']\n",
    "\n",
    "stat_cols_to_drop = [\n",
    "    \"seconds_in_bucket\",\n",
    "    \"imbalance_size\",\n",
    "    \"imbalance_buy_sell_flag\",\n",
    "    \"reference_price\",\n",
    "    \"matched_size\",\n",
    "    \"bid_price\",\n",
    "    \"ask_price\",\n",
    "    \"index_weight\",\n",
    "    \"wap_calc\",\n",
    "    \"initial_wap\",\n",
    "    \"wap_weighted\",\n",
    "    \"index_wap\",\n",
    "    \"index_wap_init\",\n",
    "    \"index_wap_move_to_init\",\n",
    "    \"overall_medvol\",\n",
    "    \"first5min_medvol\",\n",
    "    \"last5min_medvol\",\n",
    "    \"bid_plus_ask_sizes\",\n",
    "    \"imbalance_ratio\",\n",
    "    \"imb_s1\",\n",
    "    \"imb_s2\",\n",
    "    \"ask_x_size\",\n",
    "    \"bid_x_size\",\n",
    "    \"ask_minus_bid\",\n",
    "    \"bid_price_over_ask_price\",\n",
    "    \"reference_price_minus_far_price\",\n",
    "    \"reference_price_times_far_price\",\n",
    "    \"reference_price_times_near_price\",\n",
    "    \"reference_price_minus_ask_price\",\n",
    "    \"reference_price_times_ask_price\",\n",
    "    \"reference_price_ask_price_imb\",\n",
    "    \"reference_price_minus_bid_price\",\n",
    "    \"reference_price_times_bid_price\",\n",
    "    \"reference_price_bid_price_imb\",\n",
    "    \"reference_price_minus_wap\",\n",
    "    \"reference_price_times_wap\",\n",
    "    \"reference_price_wap_imb\",\n",
    "    \"far_price_minus_near_price\",\n",
    "    \"far_price_times_near_price\",\n",
    "    \"far_price_minus_ask_price\",\n",
    "    \"far_price_times_ask_price\",\n",
    "    \"far_price_minus_bid_price\",\n",
    "    \"far_price_times_bid_price\",\n",
    "    \"far_price_times_wap\",\n",
    "    \"far_price_wap_imb\",\n",
    "    \"near_price_minus_ask_price\",\n",
    "    \"near_price_times_ask_price\",\n",
    "    \"near_price_ask_price_imb\",\n",
    "    \"near_price_minus_bid_price\",\n",
    "    \"near_price_times_bid_price\",\n",
    "    \"near_price_bid_price_imb\",\n",
    "    \"near_price_minus_wap\",\n",
    "    \"near_price_wap_imb\",\n",
    "    \"ask_price_minus_bid_price\",\n",
    "    \"ask_price_times_bid_price\",\n",
    "    \"ask_price_minus_wap\",\n",
    "    \"ask_price_times_wap\",\n",
    "    \"ask_price_wap_imb\",\n",
    "    \"bid_price_minus_wap\",\n",
    "    \"bid_price_times_wap\",\n",
    "    \"bid_price_wap_imb\",\n",
    "    \"reference_price_far_price_near_price_imb2\",\n",
    "    \"reference_price_far_price_ask_price_imb2\",\n",
    "    \"reference_price_far_price_bid_price_imb2\",\n",
    "    \"reference_price_far_price_wap_imb2\",\n",
    "    \"reference_price_near_price_ask_price_imb2\",\n",
    "    \"reference_price_near_price_bid_price_imb2\",\n",
    "    \"reference_price_near_price_wap_imb2\",\n",
    "    \"reference_price_ask_price_bid_price_imb2\",\n",
    "    \"reference_price_ask_price_wap_imb2\",\n",
    "    \"reference_price_bid_price_wap_imb2\",\n",
    "    \"far_price_near_price_ask_price_imb2\",\n",
    "    \"far_price_near_price_bid_price_imb2\",\n",
    "    \"far_price_near_price_wap_imb2\",\n",
    "    \"far_price_ask_price_bid_price_imb2\",\n",
    "    \"far_price_ask_price_wap_imb2\",\n",
    "    \"far_price_bid_price_wap_imb2\",\n",
    "    \"near_price_ask_price_bid_price_imb2\",\n",
    "    \"near_price_ask_price_wap_imb2\",\n",
    "    \"near_price_bid_price_wap_imb2\",\n",
    "    \"ask_price_bid_price_wap_imb2\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"stats\"] = np.split(\n",
    "    np.nan_to_num(X[stat_cols].to_numpy(), nan=-1), indices_or_sections=len(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.189441833645105"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X) / (1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pca_prices\n",
       "-1.384228e+11    408607\n",
       "-1.384228e+11    382499\n",
       "-1.384228e+11    119580\n",
       "-1.384228e+11    113213\n",
       "-1.384228e+11    102236\n",
       "-1.384228e+11     94840\n",
       "-1.384228e+11     91490\n",
       "-1.384228e+11     88858\n",
       "-1.384228e+11     79421\n",
       "-1.384228e+11     70310\n",
       "-1.384228e+11     63146\n",
       "-1.384228e+11     56940\n",
       "-1.384228e+11     56861\n",
       "-1.384228e+11     49784\n",
       "-1.384228e+11     44292\n",
       "-1.384228e+11     39484\n",
       "-1.384228e+11     35122\n",
       "-1.384228e+11     30976\n",
       "-1.384228e+11     27834\n",
       "-1.384228e+11     24673\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.pca_prices.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"wap_category\"] = X[\"wap_price_t-60\"].apply(\n",
    "    lambda x: 0\n",
    "    if x < -10\n",
    "    else (\n",
    "        1\n",
    "        if x < -5\n",
    "        else (\n",
    "            2\n",
    "            if x < -1.5\n",
    "            else (3 if x < 1.5 else (4 if x < 5 else (5 if x < 10 else 6)))\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wap_category</th>\n",
       "      <th>wap_price_t-60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666363</th>\n",
       "      <td>6</td>\n",
       "      <td>10.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666364</th>\n",
       "      <td>4</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666365</th>\n",
       "      <td>5</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666366</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666367</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4666368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         wap_category  wap_price_t-60\n",
       "0                   1           -5.17\n",
       "1                   1           -5.29\n",
       "2                   2           -3.06\n",
       "3                   2           -3.41\n",
       "4                   3            0.56\n",
       "...               ...             ...\n",
       "4666363             6           10.05\n",
       "4666364             4            4.36\n",
       "4666365             5            5.80\n",
       "4666366             2           -2.66\n",
       "4666367             3           -0.76\n",
       "\n",
       "[4666368 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"wap_category\", \"wap_price_t-60\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"wap_category\"] = pd.qcut(X[\"wap_price_t-60\"], q=11)\n",
    "X[\"target_category\"] = pd.qcut(X[\"target\"], q=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (X[\"wap_category\"].value_counts(sort=False).reset_index().sort_values(\"wap_category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9090, 0.9091, 0.9089, 0.9092, 0.9089, 0.9091, 0.9090, 0.9095, 0.9091,\n",
       "        0.9091, 0.9091], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[\"norm_count\"] = 1 - (weights[\"count\"] / weights[\"count\"].sum())\n",
    "weights\n",
    "weight = torch.tensor(weights[\"norm_count\"].to_numpy(), device=\"cuda:0\")\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19636\\340863963.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  means_target = X.groupby('target_category')['target'].median().reset_index().reset_index(names='original_index').rename(columns={'target':'mean_target'})\n",
      "C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19636\\340863963.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  means = X.groupby('wap_category')['wap_price_t-60'].median().reset_index().reset_index(names='original_index').rename(columns={'wap_price_t-60':'mean_wap'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>wap_category</th>\n",
       "      <th>mean_wap</th>\n",
       "      <th>wap_cat_name</th>\n",
       "      <th>target_category</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>target_cat_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(-379.691, -12.61]</td>\n",
       "      <td>-17.83</td>\n",
       "      <td>0(-379.691, -12.61]</td>\n",
       "      <td>(-385.291, -10.51]</td>\n",
       "      <td>-14.830232</td>\n",
       "      <td>0(-385.291, -10.51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(-12.61, -7.66]</td>\n",
       "      <td>-9.69</td>\n",
       "      <td>1(-12.61, -7.66]</td>\n",
       "      <td>(-10.51, -6.45]</td>\n",
       "      <td>-8.109808</td>\n",
       "      <td>1(-10.51, -6.45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(-7.66, -4.74]</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>2(-7.66, -4.74]</td>\n",
       "      <td>(-6.45, -4.08]</td>\n",
       "      <td>-5.149841</td>\n",
       "      <td>2(-6.45, -4.08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(-4.74, -2.55]</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>3(-4.74, -2.55]</td>\n",
       "      <td>(-4.08, -2.3]</td>\n",
       "      <td>-3.139973</td>\n",
       "      <td>3(-4.08, -2.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(-2.55, -0.73]</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>4(-2.55, -0.73]</td>\n",
       "      <td>(-2.3, -0.78]</td>\n",
       "      <td>-1.519918</td>\n",
       "      <td>4(-2.3, -0.78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(-0.73, 0.76]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5(-0.73, 0.76]</td>\n",
       "      <td>(-0.78, 0.67]</td>\n",
       "      <td>-0.050068</td>\n",
       "      <td>5(-0.78, 0.67]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(0.76, 2.59]</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6(0.76, 2.59]</td>\n",
       "      <td>(0.67, 2.19]</td>\n",
       "      <td>1.419783</td>\n",
       "      <td>6(0.67, 2.19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(2.59, 4.8]</td>\n",
       "      <td>3.63</td>\n",
       "      <td>7(2.59, 4.8]</td>\n",
       "      <td>(2.19, 3.951]</td>\n",
       "      <td>3.030300</td>\n",
       "      <td>7(2.19, 3.951]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(4.8, 7.73]</td>\n",
       "      <td>6.13</td>\n",
       "      <td>8(4.8, 7.73]</td>\n",
       "      <td>(3.951, 6.31]</td>\n",
       "      <td>5.029440</td>\n",
       "      <td>8(3.951, 6.31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(7.73, 12.63]</td>\n",
       "      <td>9.76</td>\n",
       "      <td>9(7.73, 12.63]</td>\n",
       "      <td>(6.31, 10.37]</td>\n",
       "      <td>7.970333</td>\n",
       "      <td>9(6.31, 10.37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(12.63, 392.99]</td>\n",
       "      <td>17.68</td>\n",
       "      <td>10(12.63, 392.99]</td>\n",
       "      <td>(10.37, 387.779]</td>\n",
       "      <td>14.740229</td>\n",
       "      <td>10(10.37, 387.779]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    original_index        wap_category  mean_wap         wap_cat_name  \\\n",
       "0                0  (-379.691, -12.61]    -17.83  0(-379.691, -12.61]   \n",
       "1                1     (-12.61, -7.66]     -9.69     1(-12.61, -7.66]   \n",
       "2                2      (-7.66, -4.74]     -6.07      2(-7.66, -4.74]   \n",
       "3                3      (-4.74, -2.55]     -3.58      3(-4.74, -2.55]   \n",
       "4                4      (-2.55, -0.73]     -1.60      4(-2.55, -0.73]   \n",
       "5                5       (-0.73, 0.76]      0.01       5(-0.73, 0.76]   \n",
       "6                6        (0.76, 2.59]      1.64        6(0.76, 2.59]   \n",
       "7                7         (2.59, 4.8]      3.63         7(2.59, 4.8]   \n",
       "8                8         (4.8, 7.73]      6.13         8(4.8, 7.73]   \n",
       "9                9       (7.73, 12.63]      9.76       9(7.73, 12.63]   \n",
       "10              10     (12.63, 392.99]     17.68    10(12.63, 392.99]   \n",
       "\n",
       "       target_category  mean_target      target_cat_name  \n",
       "0   (-385.291, -10.51]   -14.830232  0(-385.291, -10.51]  \n",
       "1      (-10.51, -6.45]    -8.109808     1(-10.51, -6.45]  \n",
       "2       (-6.45, -4.08]    -5.149841      2(-6.45, -4.08]  \n",
       "3        (-4.08, -2.3]    -3.139973       3(-4.08, -2.3]  \n",
       "4        (-2.3, -0.78]    -1.519918       4(-2.3, -0.78]  \n",
       "5        (-0.78, 0.67]    -0.050068       5(-0.78, 0.67]  \n",
       "6         (0.67, 2.19]     1.419783        6(0.67, 2.19]  \n",
       "7        (2.19, 3.951]     3.030300       7(2.19, 3.951]  \n",
       "8        (3.951, 6.31]     5.029440       8(3.951, 6.31]  \n",
       "9        (6.31, 10.37]     7.970333       9(6.31, 10.37]  \n",
       "10    (10.37, 387.779]    14.740229   10(10.37, 387.779]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_target = X.groupby('target_category')['target'].median().reset_index().reset_index(names='original_index').rename(columns={'target':'mean_target'})\n",
    "means_target['target_cat_name'] = means_target['original_index'].astype(str)+means_target['target_category'].astype(str)\n",
    "means = X.groupby('wap_category')['wap_price_t-60'].median().reset_index().reset_index(names='original_index').rename(columns={'wap_price_t-60':'mean_wap'})\n",
    "means['wap_cat_name'] = means['original_index'].astype(str)+means['wap_category'].astype(str)\n",
    "means = means.merge(means_target,on='original_index')\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax()\n",
    "weight = torch.tensor(\n",
    "    [\n",
    "        1,\n",
    "        1.1,\n",
    "        1,\n",
    "        1.1,\n",
    "        1,\n",
    "    ],\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "# torch.log(torch.log(weight))\n",
    "# softmax(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe_out = ohe.fit_transform(\n",
    "    X[\"wap_category\"].to_numpy().reshape(-1, 1),\n",
    ")\n",
    "X[\"wap_target_OHE\"] = [x for x in ohe_out]\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe_out = ohe.fit_transform(\n",
    "    X[\"target_category\"].to_numpy().reshape(-1, 1),\n",
    ")\n",
    "X[\"target_OHE\"] = [x for x in ohe_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[\"target_OHE\"] = np.vsplit(ohe_out,ohe_out.shape[0])\n",
    "# X[\"target_OHE\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:03<00:00, 128.79it/s]\n",
      "  0%|          | 0/95232 [00:00<?, ?it/s]c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\utils\\torch_classes.py:87: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  self.stocksDict[stock_id].wap_daily_ohe[day] =      torch.tensor(stock_daily_data['wap_target_OHE'].to_list(),requires_grad=False,device='cuda:0')\n",
      "100%|██████████| 95232/95232 [03:21<00:00, 471.71it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(utils.torch_classes)\n",
    "trading_data = utils.torch_classes.TradingData(X,means)\n",
    "hidden_size = 64\n",
    "# trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 385, Length of test 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:01<00:00, 287.70it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 405.30it/s]\n"
     ]
    }
   ],
   "source": [
    "trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i,stocks in enumerate(trading_data.stocksDict.values()):\n",
    "#     if i==0:\n",
    "#         continue\n",
    "#     else:\n",
    "#         stocks.data_daily = []\n",
    "# trading_data.train_batches = []\n",
    "# del train\n",
    "# del X\n",
    "# X = []\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# del pca_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del pca, pca_prices_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\utils\\\\training_testing.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils.torch_classes)\n",
    "importlib.reload(utils.training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {\n",
    "    \"RMSProp\": optim.RMSprop,\n",
    "    \"Adam\": optim.Adam,\n",
    "    \"RAdam\": optim.RAdam,\n",
    "    \"NAdam\": optim.NAdam,\n",
    "    \"AdamW\": optim.AdamW,\n",
    "    \"SGD\": optim.SGD,\n",
    "    \"Rprop\": optim.Rprop,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(\n",
    "    trading_df=trading_data, config=None, prev_model_file=None, prev_model_version=450\n",
    "):\n",
    "    trading_df = trading_data\n",
    "    with wandb.init(project=\"Optviver_new\", config=config, save_code=True):\n",
    "        wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "        wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "        wandb.define_metric(\"Accuracy\", summary=\"max\")\n",
    "        config = wandb.config\n",
    "\n",
    "        input_size = len(trading_df.stocksDict[0].data_daily[0][0])\n",
    "\n",
    "        target_size_ohe = len(trading_df.stocksDict[0].target_daily_ohe[0][0])\n",
    "\n",
    "        print(target_size_ohe)\n",
    "        \n",
    "        model = utils.torch_classes.GRUNetV3(\n",
    "            input_size,\n",
    "            config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            fc0_size=config[\"fc0_size\"],\n",
    "            target_size=target_size_ohe\n",
    "        ).to(\"cuda:0\")\n",
    "\n",
    "        wandb.watch(model, log='all') \n",
    "        optimizer = optim_dict[config['optim']](model.parameters(), lr=config['learning_rate'], weight_decay=0.0001)\n",
    "        \n",
    "        config = wandb.config\n",
    "        print(config)\n",
    "        print(config['ohe_targets'])\n",
    "        if prev_model_file != None:\n",
    "            model_name = prev_model_file\n",
    "            model_loc = f\"models/{model_name}/{model_name}_{prev_model_version}.pt\"\n",
    "            model_data = torch.load(model_loc, map_location=torch.device(\"cuda:0\"))\n",
    "            print(model_data[\"model_state_dict\"].keys())\n",
    "            print(model_data.keys())\n",
    "\n",
    "            del_keys = ['fc_final.weight', 'fc_final.bias', 'fc_wap0.weight']\n",
    "            [model_data['model_state_dict'].pop(k) for k in del_keys]\n",
    "            model.load_state_dict(model_data[\"model_state_dict\"], strict=False)\n",
    "            # optimizer.load_state_dict(model_data[\"optim\"])\n",
    "\n",
    "        print(model)\n",
    "        trading_df.reset_hidden(\n",
    "            hidden_size=config[\"hidden_size\"], num_layers=config[\"num_layers\"]\n",
    "        )\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(criterion)\n",
    "        print(optimizer)\n",
    "        output = utils.training_testing.train_model(\n",
    "            trading_df, model, config, optimizer, criterion\n",
    "        )\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\utils\\\\training_testing.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils.torch_classes)\n",
    "importlib.reload(utils.training_testing)\n",
    "importlib.reload(utils.training_testing_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {\n",
    "    \"learning_rate\": 0.00008,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"batch_norm\": 1,\n",
    "    \"epochs\": 5000,\n",
    "    \"mini_batches\": 400,\n",
    "    \"fc0_size\": 256,\n",
    "    \"note\": \"New target are in \",\n",
    "    'optim': 'RMSProp',\n",
    "    'ohe_targets':means,\n",
    "}\n",
    "config = config_static\n",
    "torch.cuda.empty_cache()\n",
    "trading_data.detach_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\wandb\\run-20231214_090121-oadlp13j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/Optviver_new/runs/oadlp13j' target=\"_blank\">stellar-river-138</a></strong> to <a href='https://wandb.ai/nickojelly/Optviver_new' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/Optviver_new' target=\"_blank\">https://wandb.ai/nickojelly/Optviver_new</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/Optviver_new/runs/oadlp13j' target=\"_blank\">https://wandb.ai/nickojelly/Optviver_new/runs/oadlp13j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "{'learning_rate': 8e-05, 'hidden_size': 128, 'num_layers': 2, 'batch_norm': 1, 'epochs': 5000, 'mini_batches': 400, 'fc0_size': 256, 'note': 'New target are in ', 'optim': 'RMSProp', 'ohe_targets': '    original_index        wap_category  mean_wap         wap_cat_name  \\\\\\n0                0  (-379.691, -12.61]    -17.83  0(-379.691, -12.61]   \\n1                1     (-12.61, -7.66]     -9.69     1(-12.61, -7.66]   \\n2                2      (-7.66, -4.74]     -6.07      2(-7.66, -4.74]   \\n3                3      (-4.74, -2.55]     -3.58      3(-4.74, -2.55]   \\n4                4      (-2.55, -0.73]     -1.60      4(-2.55, -0.73]   \\n5                5       (-0.73, 0.76]      0.01       5(-0.73, 0.76]   \\n6                6        (0.76, 2.59]      1.64        6(0.76, 2.59]   \\n7                7         (2.59, 4.8]      3.63         7(2.59, 4.8]   \\n8                8         (4.8, 7.73]      6.13         8(4.8, 7.73]   \\n9                9       (7.73, 12.63]      9.76       9(7.73, 12.63]   \\n10              10     (12.63, 392.99]     17.68    10(12.63, 392.99]   \\n\\n       target_category  mean_target      target_cat_name  \\n0   (-385.291, -10.51]   -14.830232  0(-385.291, -10.51]  \\n1      (-10.51, -6.45]    -8.109808     1(-10.51, -6.45]  \\n2       (-6.45, -4.08]    -5.149841      2(-6.45, -4.08]  \\n3        (-4.08, -2.3]    -3.139973       3(-4.08, -2.3]  \\n4        (-2.3, -0.78]    -1.519918       4(-2.3, -0.78]  \\n5        (-0.78, 0.67]    -0.050068       5(-0.78, 0.67]  \\n6         (0.67, 2.19]     1.419783        6(0.67, 2.19]  \\n7        (2.19, 3.951]     3.030300       7(2.19, 3.951]  \\n8        (3.951, 6.31]     5.029440       8(3.951, 6.31]  \\n9        (6.31, 10.37]     7.970333       9(6.31, 10.37]  \\n10    (10.37, 387.779]    14.740229   10(10.37, 387.779]  '}\n",
      "    original_index        wap_category  mean_wap         wap_cat_name  \\\n",
      "0                0  (-379.691, -12.61]    -17.83  0(-379.691, -12.61]   \n",
      "1                1     (-12.61, -7.66]     -9.69     1(-12.61, -7.66]   \n",
      "2                2      (-7.66, -4.74]     -6.07      2(-7.66, -4.74]   \n",
      "3                3      (-4.74, -2.55]     -3.58      3(-4.74, -2.55]   \n",
      "4                4      (-2.55, -0.73]     -1.60      4(-2.55, -0.73]   \n",
      "5                5       (-0.73, 0.76]      0.01       5(-0.73, 0.76]   \n",
      "6                6        (0.76, 2.59]      1.64        6(0.76, 2.59]   \n",
      "7                7         (2.59, 4.8]      3.63         7(2.59, 4.8]   \n",
      "8                8         (4.8, 7.73]      6.13         8(4.8, 7.73]   \n",
      "9                9       (7.73, 12.63]      9.76       9(7.73, 12.63]   \n",
      "10              10     (12.63, 392.99]     17.68    10(12.63, 392.99]   \n",
      "\n",
      "       target_category  mean_target      target_cat_name  \n",
      "0   (-385.291, -10.51]   -14.830232  0(-385.291, -10.51]  \n",
      "1      (-10.51, -6.45]    -8.109808     1(-10.51, -6.45]  \n",
      "2       (-6.45, -4.08]    -5.149841      2(-6.45, -4.08]  \n",
      "3        (-4.08, -2.3]    -3.139973       3(-4.08, -2.3]  \n",
      "4        (-2.3, -0.78]    -1.519918       4(-2.3, -0.78]  \n",
      "5        (-0.78, 0.67]    -0.050068       5(-0.78, 0.67]  \n",
      "6         (0.67, 2.19]     1.419783        6(0.67, 2.19]  \n",
      "7        (2.19, 3.951]     3.030300       7(2.19, 3.951]  \n",
      "8        (3.951, 6.31]     5.029440       8(3.951, 6.31]  \n",
      "9        (6.31, 10.37]     7.970333       9(6.31, 10.37]  \n",
      "10    (10.37, 387.779]    14.740229   10(10.37, 387.779]  \n",
      "GRUNetV3(\n",
      "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (relu): ReLU()\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (batch_norm): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (drop_1): Dropout(p=0.5, inplace=False)\n",
      "  (fc0): Linear(in_features=22, out_features=128, bias=True)\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc_final): Linear(in_features=256, out_features=11, bias=True)\n",
      "  (fc_wap0): Linear(in_features=11, out_features=64, bias=True)\n",
      "  (fc_wap_relu): ReLU()\n",
      "  (fc_wap1): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc_target0): Linear(in_features=11, out_features=64, bias=True)\n",
      "  (fc_target_relu): ReLU()\n",
      "  (fc_target1): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 8e-05\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cae3b4743674e09856e7fc2802f2b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19636\\815035850.py\", line 50, in model_pipeline\n",
      "    output = utils.training_testing.train_model(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\utils\\training_testing.py\", line 98, in train_model\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d120687f0704d24af39fc9652d7334f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='514.872 MB of 514.872 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▁▄▅▆▇▇█████████▇▇▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>L1_loss_wap_epoch</td><td>▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_loss</td><td>█▆▄▄▄▄▃▃▄▄▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>loss_1</td><td>█▆▃▄▅▃▃▂▃▃▂▁▃▂▂▃▃▃▄▃▂▃▃▂▂▂▂▁▂▃▃▃▂▃▃▂▃▁▂▁</td></tr><tr><td>losst_to_zero</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>output_sd</td><td>▂▄▃▁▁▁▂▂▃▃▄▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████</td></tr><tr><td>relu_sum</td><td>██▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_epoch_loss</td><td>█▆▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_target_l1</td><td>▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▇▇█</td></tr><tr><td>wap_pred_loss</td><td>▆▁▁▁▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>L1_loss_wap_epoch</td><td>6.94713</td></tr><tr><td>epoch</td><td>1138</td></tr><tr><td>epoch_loss</td><td>86.05536</td></tr><tr><td>loss_1</td><td>87.93306</td></tr><tr><td>losst_to_zero</td><td>6.17443</td></tr><tr><td>output_sd</td><td>0.4905</td></tr><tr><td>relu_sum</td><td>650515.75</td></tr><tr><td>val_epoch_loss</td><td>2.33389</td></tr><tr><td>val_loss</td><td>2.31798</td></tr><tr><td>val_loss_target_l1</td><td>6.21852</td></tr><tr><td>wap_pred_loss</td><td>10.36688</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-river-138</strong> at: <a href='https://wandb.ai/nickojelly/Optviver_new/runs/oadlp13j' target=\"_blank\">https://wandb.ai/nickojelly/Optviver_new/runs/oadlp13j</a><br/>Synced 6 W&B file(s), 342 media file(s), 342 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231214_090121-oadlp13j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m CUDA_LAUNCH_BLOCKING \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# output = model_pipeline(trading_data, config_static,)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrading_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_static\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 50\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[1;34m(trading_df, config, prev_model_file, prev_model_version)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(criterion)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(optimizer)\n\u001b[1;32m---> 50\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_testing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrading_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\utils\\training_testing.py:98\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(trading_df, model, config, optimizer, criterion)\u001b[0m\n\u001b[0;32m     96\u001b[0m L1_loss_target \u001b[38;5;241m=\u001b[39m reg_L1(output_target, Y)\n\u001b[0;32m     97\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m L1_loss_wap \u001b[38;5;241m+\u001b[39m L1_loss_target\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 98\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_loss:\n\u001b[0;32m    100\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING = 1\n",
    "# output = model_pipeline(trading_data, config_static,)\n",
    "output = model_pipeline(trading_data, config_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.3.5.ipynb Cell 64\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3.5.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mrand(\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.rand(10).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: upepev1k\n",
      "Sweep URL: https://wandb.ai/nickojelly/Optiver%20Sweeps/sweeps/upepev1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t85ko0dj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf0_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tf1_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\wandb\\run-20231208_141040-t85ko0dj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/Optiver%20Sweeps/runs/t85ko0dj' target=\"_blank\">unique-sweep-1</a></strong> to <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps/sweeps/upepev1k' target=\"_blank\">https://wandb.ai/nickojelly/Optiver%20Sweeps/sweeps/upepev1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps' target=\"_blank\">https://wandb.ai/nickojelly/Optiver%20Sweeps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps/sweeps/upepev1k' target=\"_blank\">https://wandb.ai/nickojelly/Optiver%20Sweeps/sweeps/upepev1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps/runs/t85ko0dj' target=\"_blank\">https://wandb.ai/nickojelly/Optiver%20Sweeps/runs/t85ko0dj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_18468\\3034068021.py\", line 10, in model_pipeline\n",
      "    model = utils.torch_classes.GRUNetV3(input_size,config['hidden_size'],num_layers=config['num_layers']).to('cuda:0')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1160, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 810, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 213, in _apply\n",
      "    ret = super()._apply(fn, recurse)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 833, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1158, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b8f16177cf4a4a8fc96eece495e9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.066 MB of 0.066 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-1</strong> at: <a href='https://wandb.ai/nickojelly/Optiver%20Sweeps/runs/t85ko0dj' target=\"_blank\">https://wandb.ai/nickojelly/Optiver%20Sweeps/runs/t85ko0dj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231208_141040-t85ko0dj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"val_epoch_loss\", \"goal\": \"minimize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"values\": [\"adamW\", \"adam\", \"SGD\", \"RMSprop\"]},\n",
    "    \"f0_layer_size\": {\"values\": [128]},\n",
    "    \"f1_layer_size\": {\"values\": [64]},\n",
    "    \"num_layers\": {\"values\": [2]},\n",
    "    \"hidden_size\": {\"values\": [128, 256, 512]},\n",
    "    \"learning_rate\": {\"values\": [0.001, 0.0005, 0.0001, 0.00005, 0.00001]},\n",
    "    \"epochs\": {\"value\": 500}\n",
    "    # 'batch_norm':{'values':[0,1,2]}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Optiver Sweeps\")\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
