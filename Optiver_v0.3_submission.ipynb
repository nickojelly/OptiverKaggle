{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import utils.public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import utils.torch_classes as torch_classes\n",
    "from utils.model_saver import model_saver_wandb as model_saver\n",
    "import utils.training_testing_double \n",
    "from itertools import combinations\n",
    "import importlib\n",
    "import gc\n",
    "from utils.consts import STATS_COLS\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0', 'gru.weight_ih_l1', 'gru.weight_hh_l1', 'gru.bias_ih_l1', 'gru.bias_hh_l1', 'batch_norm.weight', 'batch_norm.bias', 'batch_norm.running_mean', 'batch_norm.running_var', 'batch_norm.num_batches_tracked', 'layer_norm.weight', 'layer_norm.bias', 'layer_norm2.weight', 'layer_norm2.bias', 'fc0.weight', 'fc0.bias', 'fc1.weight', 'fc1.bias', 'fc_final.weight', 'fc_final.bias', 'fc_reg0.weight', 'fc_reg0.bias', 'fc_reg1.weight', 'fc_reg1.bias', 'fc_reg2.weight', 'fc_reg2.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch_classes.GRUNetV4(22,128,num_layers=2,target_size=5)\n",
    "model_loc = f\"models/curious-dew-316/curious-dew-316_20.pt\"\n",
    "model_data = torch.load(model_loc,map_location=torch.device('cpu'))\n",
    "print(model_data['model_state_dict'].keys())\n",
    "model.load_state_dict(model_data['model_state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_feather('train.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(data=list(zip(range(0,201),weights)),columns=['stock_id','index_weight'])\n",
    "train = train.merge(weights_df,on='stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\"\n",
    "median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_data = torch_classes.TradingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "1\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "2\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "3\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "4\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "trading_data.fill_hidden_states_for_test(model_data['db_train'])\n",
    "# trading_data.reset_hidden(64,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True)\n",
    "    \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + train['ask_size']\n",
    "#     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "#     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0) \n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "    df['ask_x_size'] = df.eval('ask_size*ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size*bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        \n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        # 'date_id', \n",
    "        'reference_price_far_price_imb',\n",
    "        'reference_price_minus_near_price',\n",
    "        'reference_price_near_price_imb',\n",
    "        'far_price_near_price_imb',\n",
    "        'far_price_ask_price_imb',\n",
    "        'far_price_bid_price_imb',\n",
    "        'far_price_minus_wap',\n",
    "        'std_size',\n",
    "        'bid_size_over_ask_size',\n",
    "        'ask_price_bid_price_imb',\n",
    "        'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prev_race(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'initial_wap'] = df_g['wap_calc'].transform('first')\n",
    "    df[f'initial_bid_size'] = df_g['bid_size'].transform('first')\n",
    "    df[f'initial_ask_size'] = df_g['ask_size'].transform('first')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap'] = df_g['wap_weighted'].transform('mean')\n",
    "    return(df)\n",
    "\n",
    "def generate_index_2(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap_init'] = df_g['index_wap'].transform('first')\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_eng(train):\n",
    "\n",
    "    train['wap_weighted'] = train['wap']*train['index_weight']\n",
    "    train_g = train.groupby(['stock_id','date_id'])\n",
    "    train = generate_prev_race(train,train_g)\n",
    "\n",
    "    train_g = train.groupby(['seconds_in_bucket','date_id'])\n",
    "    train = generate_index(train,train_g)\n",
    "\n",
    "\n",
    "    train['wap_move_to_init'] = train['wap_calc']/train['initial_wap']\n",
    "    train_g = train.groupby(['date_id'])\n",
    "    train = generate_index_2(train,train_g)\n",
    "\n",
    "    train['index_wap_move_to_init'] = train['index_wap']/train['index_wap_init']\n",
    "\n",
    "\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mfeat_eng\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m prices \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m c) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m c) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m60\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m c)\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(prices)\n",
      "Cell \u001b[1;32mIn[18], line 34\u001b[0m, in \u001b[0;36mfeat_eng\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     30\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_imb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)/(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m combinations(prices, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m     max_ \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     min_ \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mlist\u001b[39m(c)]\u001b[38;5;241m.\u001b[39mmin(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     mid_ \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mlist\u001b[39m(c)]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39mmin_\u001b[38;5;241m-\u001b[39mmax_\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\frame.py:11298\u001b[0m, in \u001b[0;36mDataFrame.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11290\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m  11292\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11296\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11297\u001b[0m ):\n\u001b[1;32m> 11298\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11300\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\generic.py:11976\u001b[0m, in \u001b[0;36mNDFrame.max\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11969\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[0;32m  11970\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11971\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11974\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11975\u001b[0m ):\n\u001b[1;32m> 11976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11979\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  11983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  11951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\frame.py:11208\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11207\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mastype(out_dtype)\n\u001b[1;32m> 11208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m  11209\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m  11210\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m  11211\u001b[0m     \u001b[38;5;66;03m# Even if we are object dtype, follow numpy and return\u001b[39;00m\n\u001b[0;32m  11212\u001b[0m     \u001b[38;5;66;03m#  float64, see test_apply_funcs_over_empty\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\numpy\\core\\_methods.py:58\u001b[0m, in \u001b[0;36m_any\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_any\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y = train[\"target\"].values\n",
    "X = feat_eng(train)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "print(prices)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "# prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X[\"pca_prices\"] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.Booster(model_file=\"data/lgbm_model_new_t60.lgb\")\n",
    "X = train\n",
    "X_train = X[[c for c in X.columns if (\"target\" not in c) and (\"60\" not in c)]].drop(\n",
    "    columns=[\"delta_wap\", \"date_id\"]\n",
    ")\n",
    "lgbm_preds = lgbm.predict(X_train)\n",
    "X[\"lgbm_preds\"] = lgbm_preds\n",
    "\n",
    "del pca_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preds(test, trading_data:torch_classes.TradingData, model:torch_classes.GRUNet):\n",
    "    test['stats']  = pd.Series(test[STATS_COLS].fillna(-1).values.tolist())\n",
    "    stock_ids = test.stock_id.unique().tolist()\n",
    "    stocks = [trading_data.stocksDict[x] for x in stock_ids]\n",
    "    hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1)\n",
    "    \n",
    "    X = [torch.tensor(x) for x in test['stats'].tolist()]\n",
    "    \n",
    "    Xstacked = torch.stack(X)\n",
    "    \n",
    "    Xviewed = pack_sequence(Xstacked.view(-1,1,12))\n",
    "    \n",
    "    output,hidden_out = model(Xviewed,hidden)\n",
    "    \n",
    "    hidden_out = hidden_out.transpose(0,1)\n",
    "    \n",
    "    [setattr(obj, 'hidden', val.detach()) for obj, val in zip(stocks,hidden_out)]\n",
    "    \n",
    "    output = output.flatten().tolist()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0     4192980         0      386                  0      2555434.64   \n",
      "1     4192981         1      386                  0       274697.82   \n",
      "2     4192982         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id                                              stats  \n",
      "0  386_0_0  [0.0, 2555434.64, -1.0, 1.000032, 9966697.63, ...  \n",
      "1  386_0_1  [0.0, 274697.82, 1.0, 0.999714, 1324398.6, -1....  \n",
      "2  386_0_2  [0.0, 415532.77, 1.0, 0.999826, 2463160.51, -1...  \n",
      "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0         0      386                  0      2555434.64   \n",
      "1         1      386                  0       274697.82   \n",
      "2         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id  \n",
      "0  386_0_0  \n",
      "1  386_0_1  \n",
      "2  386_0_2  \n",
      "   Unnamed: 0  stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0     4192980         0      386                  0      2555434.64   \n",
      "1     4192981         1      386                  0       274697.82   \n",
      "2     4192982         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id                                              stats  \n",
      "0  386_0_0  [0.0, 2555434.64, -1.0, 1.000032, 9966697.63, ...  \n",
      "1  386_0_1  [0.0, 274697.82, 1.0, 0.999714, 1324398.6, -1....  \n",
      "2  386_0_2  [0.0, 415532.77, 1.0, 0.999826, 2463160.51, -1...  \n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['pca_prices'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.3_submission.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test \u001b[39m=\u001b[39m variable_eng(test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m test \u001b[39m=\u001b[39m feat_eng(test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m preditcions \u001b[39m=\u001b[39m gen_preds(test,trading_data,model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sample_prediction[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preditcions\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m test_df \u001b[39m=\u001b[39m test\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.3_submission.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_preds\u001b[39m(test, trading_data:torch_classes\u001b[39m.\u001b[39mTradingData, model:torch_classes\u001b[39m.\u001b[39mGRUNet):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     test[\u001b[39m'\u001b[39m\u001b[39mstats\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(test[STATS_COLS]\u001b[39m.\u001b[39mfillna(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     stock_ids \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mstock_id\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.3_submission.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     stocks \u001b[39m=\u001b[39m [trading_data\u001b[39m.\u001b[39mstocksDict[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m stock_ids]\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['pca_prices'] not in index\""
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    if counter == 0:\n",
    "        print(test.head(3))\n",
    "        print(revealed_targets.head(3))\n",
    "        print(sample_prediction.head(3))\n",
    "    print(counter)\n",
    "    test['wap_calc'] = (test['bid_price']*test['ask_size']+test['ask_price']*test['bid_size'])/(test['ask_size']+test['bid_size'])\n",
    "    test = test.merge(weights_df,on='stock_id')\n",
    "    test = variable_eng(test)\n",
    "    test = feat_eng(test)\n",
    "    test = X['pca_prices'] = pca_prices.transform(X[prices].fillna(1))\n",
    "    preditcions = gen_preds(test,trading_data,model)\n",
    "    \n",
    "    sample_prediction['pred'] = preditcions\n",
    "    test_df = test\n",
    "    # print(preditcions)\n",
    "    # break\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in iter_test:\n",
    "    \n",
    "#     test_df = i[0]\n",
    "#     print(test_df)\n",
    "#     test_df['stats']  = pd.Series(test_df[stats_cols].fillna(-1).values.tolist())\n",
    "#     stock_ids = test_df.stock_id.unique()\n",
    "#     stocks = [trading_data.stocksDict[x] for x in stock_ids] \n",
    "#     hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1)\n",
    "#     X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "#     X = torch.stack(X)\n",
    "#     X = pack_sequence(X.view(-1,1,12))\n",
    "\n",
    "    \n",
    "#     model.eval()\n",
    "#     output,hidden = model(X,hidden)\n",
    "#     [setattr(obj, 'hidden', val.detach()) for obj, val in zip(stocks,hidden)]\n",
    "#     print(output)\n",
    "#     test_df['taget'] = output.flatten().tolist()\n",
    "#     # test_df['actual'] = test_df['target']\n",
    "#     env.predict(test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.5</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0_0_0</td>\n",
       "      <td>[0.0, 3180602.69, 1.0, 0.999812, 13380276.64, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target row_id  \\\n",
       "0         NaN   0.999812   60651.5   1.000026   8493.03  1.0 -3.029704  0_0_0   \n",
       "\n",
       "                                               stats  \n",
       "0  [0.0, 3180602.69, 1.0, 0.999812, 13380276.64, ...  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8575,  0.7445, -0.8014,  0.7816, -0.5938, -0.7823, -0.7967,\n",
      "          -0.5086,  0.5378, -0.0737, -0.5103, -0.5201, -0.2461, -0.4879,\n",
      "          -0.3435, -0.1746, -0.1386,  0.0818, -0.7184, -0.3409, -0.6650,\n",
      "           0.9997, -0.7376, -0.4719,  0.5599,  0.6262,  0.6931, -0.9579,\n",
      "          -0.6052,  0.0718,  0.6607,  0.6729,  0.0845, -0.4968, -0.6447,\n",
      "          -0.9867,  0.6466, -0.9892, -0.7533,  0.7768, -0.3308, -0.0147,\n",
      "           0.9768,  0.5592,  0.0995, -0.1919,  0.9054,  0.9997, -0.0796,\n",
      "          -0.7784, -0.9714, -0.4716, -0.5839,  0.9843, -0.7999,  0.9457,\n",
      "           0.4040, -1.0000, -0.4622, -0.3323,  0.7707,  0.3389,  0.3091,\n",
      "          -0.8781]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.8575,  0.7445, -0.8015,  0.7816, -0.5938, -0.7823, -0.7968,\n",
      "          -0.5089,  0.5378, -0.0737, -0.5103, -0.5201, -0.2461, -0.4878,\n",
      "          -0.3442, -0.1746, -0.1390,  0.0821, -0.7184, -0.3408, -0.6650,\n",
      "           0.9997, -0.7375, -0.4719,  0.5599,  0.6262,  0.6941, -0.9582,\n",
      "          -0.6053,  0.0717,  0.6607,  0.6729,  0.0846, -0.4968, -0.6447,\n",
      "          -0.9867,  0.6467, -0.9892, -0.7545,  0.7768, -0.3309, -0.0147,\n",
      "           0.9768,  0.5592,  0.0995, -0.1919,  0.9054,  0.9997, -0.0792,\n",
      "          -0.7785, -0.9714, -0.4716, -0.5839,  0.9844, -0.8004,  0.9456,\n",
      "           0.4046, -1.0000, -0.4622, -0.3323,  0.7706,  0.3391,  0.3091,\n",
      "          -0.8787]]], grad_fn=<StackBackward0>)\n",
      "-1.4035744667053223\n",
      "tensor([[[-0.2776,  0.7300,  0.4684,  0.4859, -0.6417, -0.6419, -0.0442,\n",
      "           0.2894,  0.9964, -0.4556, -0.2518, -0.9489, -0.1862,  0.2100,\n",
      "          -0.1263, -0.0886, -0.0576,  1.0000,  0.0706,  0.5752,  0.1624,\n",
      "           0.9595,  0.3823,  0.0916,  0.5848, -0.2474,  0.3140, -0.9481,\n",
      "          -0.6858, -0.0265,  0.7529,  0.6486, -0.3356,  0.2370, -0.9770,\n",
      "          -0.9345,  0.5451, -0.9323, -0.3058,  0.4803, -0.3513,  0.3643,\n",
      "           0.9948,  0.6030,  0.0194, -0.2567,  0.3477,  0.3218, -0.0557,\n",
      "          -0.2221, -0.9273, -0.2433,  0.3337,  0.7029, -0.8221,  0.9600,\n",
      "           0.1987, -1.0000,  0.3080, -0.5119,  0.5234,  0.2743, -0.5009,\n",
      "          -0.7657]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.2776,  0.7300,  0.4684,  0.4859, -0.6417, -0.6418, -0.0444,\n",
      "           0.2895,  0.9964, -0.4556, -0.2519, -0.9489, -0.1863,  0.2100,\n",
      "          -0.1263, -0.0886, -0.0578,  1.0000,  0.0706,  0.5750,  0.1624,\n",
      "           0.9596,  0.3820,  0.0917,  0.5844, -0.2474,  0.3146, -0.9484,\n",
      "          -0.6861, -0.0265,  0.7529,  0.6489, -0.3353,  0.2370, -0.9770,\n",
      "          -0.9346,  0.5452, -0.9324, -0.3060,  0.4800, -0.3512,  0.3643,\n",
      "           0.9948,  0.6030,  0.0194, -0.2567,  0.3478,  0.3225, -0.0557,\n",
      "          -0.2225, -0.9273, -0.2434,  0.3337,  0.7034, -0.8229,  0.9601,\n",
      "           0.1994, -1.0000,  0.3080, -0.5119,  0.5233,  0.2744, -0.5009,\n",
      "          -0.7666]]], grad_fn=<StackBackward0>)\n",
      "-1.020544171333313\n",
      "tensor([[[-3.3288e-01,  7.3953e-01,  2.2678e-01,  6.6525e-01, -5.3614e-01,\n",
      "          -1.7086e-01, -4.8577e-01, -2.2119e-01,  8.7855e-01, -3.6909e-01,\n",
      "          -4.3749e-01, -9.4345e-01, -2.2136e-01,  2.5511e-01,  1.5535e-01,\n",
      "           3.3959e-02, -2.5780e-01,  9.9775e-01, -3.1008e-01, -8.8997e-04,\n",
      "          -3.0357e-01,  9.5762e-01, -7.5892e-01, -2.8284e-01,  4.9396e-01,\n",
      "          -2.3661e-01,  1.9739e-01, -8.6915e-01, -6.8575e-01, -3.7661e-01,\n",
      "           7.8987e-01,  6.3488e-01, -6.9471e-01, -1.1236e-01, -9.5045e-01,\n",
      "          -9.6054e-01,  6.2565e-01, -9.9805e-01, -6.3082e-01, -8.1757e-01,\n",
      "          -1.1894e-01,  5.4986e-01,  9.1603e-01,  4.6996e-01,  1.3606e-01,\n",
      "          -1.9484e-01,  4.1610e-01,  7.9261e-01,  3.9763e-02, -7.0268e-01,\n",
      "          -9.3267e-01, -2.9038e-01, -6.8203e-02,  4.8912e-01, -8.3270e-01,\n",
      "           8.9056e-01,  1.5891e-02, -1.0000e+00, -2.8816e-02,  8.5550e-02,\n",
      "           7.8856e-01,  3.7089e-01, -4.3351e-01, -7.6899e-01]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-3.3292e-01,  7.3953e-01,  2.2671e-01,  6.6525e-01, -5.3614e-01,\n",
      "          -1.7019e-01, -4.8593e-01, -2.2119e-01,  8.7853e-01, -3.6908e-01,\n",
      "          -4.3753e-01, -9.4345e-01, -2.2112e-01,  2.5495e-01,  1.5530e-01,\n",
      "           3.3962e-02, -2.5878e-01,  9.9779e-01, -3.1008e-01, -6.6736e-04,\n",
      "          -3.0362e-01,  9.5766e-01, -7.5894e-01, -2.8285e-01,  4.9331e-01,\n",
      "          -2.3659e-01,  1.9788e-01, -8.6952e-01, -6.8639e-01, -3.7661e-01,\n",
      "           7.8987e-01,  6.3522e-01, -6.9472e-01, -1.1238e-01, -9.5045e-01,\n",
      "          -9.6057e-01,  6.2572e-01, -9.9806e-01, -6.3209e-01, -8.1807e-01,\n",
      "          -1.1857e-01,  5.4987e-01,  9.1603e-01,  4.6996e-01,  1.3608e-01,\n",
      "          -1.9484e-01,  4.1679e-01,  7.9319e-01,  3.9803e-02, -7.0288e-01,\n",
      "          -9.3267e-01, -2.9045e-01, -6.8420e-02,  4.8913e-01, -8.3323e-01,\n",
      "           8.9066e-01,  1.6115e-02, -1.0000e+00, -2.8785e-02,  8.5770e-02,\n",
      "           7.8853e-01,  3.7098e-01, -4.3351e-01, -7.6995e-01]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "-2.2814908027648926\n",
      "tensor([[[-0.7710,  1.0000, -0.2718, -0.2762, -0.9859, -0.9954,  0.9904,\n",
      "          -0.9976,  0.6406, -0.9927, -0.9795, -0.9231, -0.2883, -0.0886,\n",
      "          -0.9993, -0.9989, -0.9985,  0.9992,  0.0962,  0.9905,  0.3119,\n",
      "           0.9669,  0.9974, -0.3228,  0.9932,  0.4761,  0.9908, -0.9905,\n",
      "          -0.9986, -0.2445,  0.2121, -0.9735,  0.7559, -0.6735, -0.0535,\n",
      "          -0.8444, -0.0768,  0.5836,  0.3734,  0.6637, -0.8054,  0.8723,\n",
      "           0.9998,  0.9959, -0.9993, -0.9996, -0.9986, -0.2715, -0.5446,\n",
      "          -0.3907, -0.3915, -0.9997,  0.0719,  0.7859, -0.8440, -0.9910,\n",
      "          -0.9885, -0.9997, -0.7936, -0.9589,  0.8983, -0.8311, -0.7800,\n",
      "           0.6210]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.7711,  1.0000, -0.2740, -0.2763, -0.9860, -0.9954,  0.9904,\n",
      "          -0.9976,  0.6423, -0.9927, -0.9797, -0.9231, -0.2883, -0.0887,\n",
      "          -0.9993, -0.9989, -0.9985,  0.9992,  0.0962,  0.9905,  0.3119,\n",
      "           0.9669,  0.9974, -0.3228,  0.9932,  0.4764,  0.9909, -0.9905,\n",
      "          -0.9986, -0.2445,  0.2120, -0.9735,  0.7578, -0.6735, -0.0537,\n",
      "          -0.8440, -0.0768,  0.5837,  0.3720,  0.6637, -0.8059,  0.8718,\n",
      "           0.9998,  0.9959, -0.9993, -0.9996, -0.9986, -0.2706, -0.5443,\n",
      "          -0.3907, -0.3920, -0.9997,  0.0719,  0.7857, -0.8444, -0.9910,\n",
      "          -0.9885, -0.9997, -0.7937, -0.9589,  0.8984, -0.8315, -0.7800,\n",
      "           0.6228]]], grad_fn=<StackBackward0>)\n",
      "-2.153714656829834\n",
      "tensor([[[-0.3425,  0.8064,  0.0902,  0.5665, -0.4546, -0.1501, -0.5052,\n",
      "          -0.1551,  0.9104, -0.2300, -0.3282, -0.9411, -0.0474,  0.4348,\n",
      "           0.1218,  0.1773, -0.1476,  0.9968, -0.2143,  0.0098, -0.1239,\n",
      "           0.9582, -0.7103, -0.1943,  0.5150, -0.2317,  0.2028, -0.7747,\n",
      "          -0.7960, -0.2437,  0.8126,  0.7476, -0.8604,  0.0579, -0.9651,\n",
      "          -0.9471,  0.6807, -0.9935, -0.7268, -0.8865,  0.0078,  0.5871,\n",
      "           0.8481,  0.6001,  0.2528, -0.0831,  0.3801,  0.7444,  0.1364,\n",
      "          -0.7412, -0.9202, -0.0644, -0.1209,  0.1931, -0.7230,  0.8934,\n",
      "           0.0082, -1.0000,  0.0481, -0.1149,  0.7336,  0.4315, -0.5373,\n",
      "          -0.7494]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.3425,  0.8064,  0.0902,  0.5665, -0.4546, -0.1495, -0.5054,\n",
      "          -0.1551,  0.9104, -0.2300, -0.3282, -0.9411, -0.0469,  0.4348,\n",
      "           0.1218,  0.1773, -0.1482,  0.9969, -0.2143,  0.0101, -0.1239,\n",
      "           0.9582, -0.7105, -0.1943,  0.5145, -0.2317,  0.2031, -0.7743,\n",
      "          -0.7965, -0.2437,  0.8126,  0.7478, -0.8604,  0.0579, -0.9651,\n",
      "          -0.9471,  0.6808, -0.9935, -0.7279, -0.8869,  0.0082,  0.5871,\n",
      "           0.8482,  0.6001,  0.2528, -0.0831,  0.3807,  0.7449,  0.1364,\n",
      "          -0.7413, -0.9202, -0.0645, -0.1212,  0.1929, -0.7237,  0.8935,\n",
      "           0.0083, -1.0000,  0.0482, -0.1147,  0.7336,  0.4316, -0.5373,\n",
      "          -0.7505]]], grad_fn=<StackBackward0>)\n",
      "-3.0033774375915527\n"
     ]
    }
   ],
   "source": [
    "for i,data in test_df.iterrows():\n",
    "    hidden = torch.stack([trading_data.stocksDict[data['stock_id']].hidden])\n",
    "    print(hidden)\n",
    "    hidden = torch.stack([trading_data.stocksDict[data['stock_id']].hidden]).transpose(0,1)\n",
    "    X = torch.tensor(data['stats']).view(-1,12,1)\n",
    "    model.eval()\n",
    "    output,hidden  = model(X,hidden,test=True)\n",
    "    trading_data.stocksDict[data['stock_id']].hidden = hidden[0]\n",
    "    print(hidden)\n",
    "    print(output.flatten().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['stats']  = pd.Series(test_df[stats_cols].fillna(-1).values.tolist())\n",
    "stock_ids = test_df.stock_id.unique()\n",
    "hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1)\n",
    "X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "# X = pack_sequence(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1240],\n",
       "         [ 1.0552],\n",
       "         [-2.5545],\n",
       "         [ 2.2515],\n",
       "         [-1.9348],\n",
       "         [ 3.7566],\n",
       "         [-0.6949],\n",
       "         [-2.2269],\n",
       "         [-2.6248],\n",
       "         [ 6.1143]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "X = torch.stack(X).view(-1,12,1)\n",
    "# X = pack_sequence(X)\n",
    "model.eval()\n",
    "output,hidden  = model(X,hidden,test=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1262, -0.1012, -0.2037,  0.1888,  0.0976, -0.2847, -0.5807,\n",
       "          -0.5896, -0.0159,  0.2682, -0.5628,  0.1121, -0.1300,  0.2515,\n",
       "           0.1864,  0.0224,  0.0196, -0.1425, -0.6340, -0.5149, -0.6020,\n",
       "          -0.2689, -0.0297, -0.6029,  0.4218,  0.0321,  0.1283, -0.3335,\n",
       "           0.2974, -0.4182,  0.1575,  0.3770, -0.1936, -0.5595,  0.2087,\n",
       "          -0.1358,  0.1713,  0.1705,  0.0112, -0.2112, -0.5883, -0.2184,\n",
       "           0.6552,  0.0014, -0.0707, -0.0010,  0.4840,  0.5455, -0.3142,\n",
       "          -0.4542, -0.2142, -0.2478, -0.2938, -0.1563, -0.5573,  0.7317,\n",
       "          -0.0501, -0.3461, -0.5378,  0.3539, -0.1586,  0.4133,  0.1239,\n",
       "          -0.1093]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  3.1806e+06,  1.0000e+00,  9.9981e-01,  1.3380e+07,\n",
       "          -1.0000e+00, -1.0000e+00,  9.9981e-01,  6.0652e+04,  1.0000e+00,\n",
       "           8.4930e+03,  1.0000e+00]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(torch_classes)\n",
    "trading_data = torch_classes.TradingData(train)\n",
    "hidden_size = 64\n",
    "# trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(trading_df:torch_classes.TradingData, config:dict):\n",
    "    with wandb.init(project=\"Optviver\", config=config,save_code=True):\n",
    "        wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "        wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "        model = torch_classes.GRUNet(12,hidden_size).to('cuda:0')\n",
    "        config = wandb.config\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        trading_df.reset_hidden(config['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        training_testing.train_model(trading_df,model,config,optimizer,criterion)\n",
    "\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {'learning_rate':0.0001, 'hidden_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(trading_data, config_static)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
