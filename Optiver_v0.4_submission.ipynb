{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import utils.public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import utils.torch_classes as torch_classes\n",
    "from utils.model_saver import model_saver_wandb as model_saver\n",
    "import utils.training_testing_double \n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "import importlib\n",
    "import gc\n",
    "from utils.conts import stat_col_full\n",
    "# from utils.conts import lgbm_columns\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_columns = ['stock_id',\n",
    " 'seconds_in_bucket',\n",
    " 'imbalance_size',\n",
    " 'imbalance_buy_sell_flag',\n",
    " 'reference_price',\n",
    " 'matched_size',\n",
    " 'far_price',\n",
    " 'near_price',\n",
    " 'bid_price',\n",
    " 'bid_size',\n",
    " 'ask_price',\n",
    " 'ask_size',\n",
    " 'wap',\n",
    " 'index_weight',\n",
    " 'wap_calc',\n",
    " 'wap_weighted',\n",
    " 'initial_wap',\n",
    " 'initial_bid_size',\n",
    " 'initial_ask_size',\n",
    " 'bid_price_t10',\n",
    " 'ask_price_t10',\n",
    " 'bid_size_t10',\n",
    " 'ask_size_t10',\n",
    " 'wap_t10',\n",
    " 'index_wap',\n",
    " 'wap_move_to_init',\n",
    " 'index_wap_init',\n",
    " 'index_wap_move_to_init',\n",
    " 'wap_prev_move',\n",
    " 'bid_price_prev_move',\n",
    " 'ask_price_prev_move',\n",
    " 'overall_medvol',\n",
    " 'first5min_medvol',\n",
    " 'last5min_medvol',\n",
    " 'bid_plus_ask_sizes',\n",
    " 'imbalance_ratio',\n",
    " 'imb_s1',\n",
    " 'imb_s2',\n",
    " 'ask_x_size',\n",
    " 'bid_x_size',\n",
    " 'ask_minus_bid',\n",
    " 'bid_price_over_ask_price',\n",
    " 'reference_price_minus_far_price',\n",
    " 'reference_price_times_far_price',\n",
    " 'reference_price_times_near_price',\n",
    " 'reference_price_minus_ask_price',\n",
    " 'reference_price_times_ask_price',\n",
    " 'reference_price_ask_price_imb',\n",
    " 'reference_price_minus_bid_price',\n",
    " 'reference_price_times_bid_price',\n",
    " 'reference_price_bid_price_imb',\n",
    " 'reference_price_minus_wap',\n",
    " 'reference_price_times_wap',\n",
    " 'reference_price_wap_imb',\n",
    " 'far_price_minus_near_price',\n",
    " 'far_price_times_near_price',\n",
    " 'far_price_minus_ask_price',\n",
    " 'far_price_times_ask_price',\n",
    " 'far_price_minus_bid_price',\n",
    " 'far_price_times_bid_price',\n",
    " 'far_price_times_wap',\n",
    " 'far_price_wap_imb',\n",
    " 'near_price_minus_ask_price',\n",
    " 'near_price_times_ask_price',\n",
    " 'near_price_ask_price_imb',\n",
    " 'near_price_minus_bid_price',\n",
    " 'near_price_times_bid_price',\n",
    " 'near_price_bid_price_imb',\n",
    " 'near_price_minus_wap',\n",
    " 'near_price_wap_imb',\n",
    " 'ask_price_minus_bid_price',\n",
    " 'ask_price_times_bid_price',\n",
    " 'ask_price_minus_wap',\n",
    " 'ask_price_times_wap',\n",
    " 'ask_price_wap_imb',\n",
    " 'bid_price_minus_wap',\n",
    " 'bid_price_times_wap',\n",
    " 'bid_price_wap_imb',\n",
    " 'reference_price_far_price_near_price_imb2',\n",
    " 'reference_price_far_price_ask_price_imb2',\n",
    " 'reference_price_far_price_bid_price_imb2',\n",
    " 'reference_price_far_price_wap_imb2',\n",
    " 'reference_price_near_price_ask_price_imb2',\n",
    " 'reference_price_near_price_bid_price_imb2',\n",
    " 'reference_price_near_price_wap_imb2',\n",
    " 'reference_price_ask_price_bid_price_imb2',\n",
    " 'reference_price_ask_price_wap_imb2',\n",
    " 'reference_price_bid_price_wap_imb2',\n",
    " 'far_price_near_price_ask_price_imb2',\n",
    " 'far_price_near_price_bid_price_imb2',\n",
    " 'far_price_near_price_wap_imb2',\n",
    " 'far_price_ask_price_bid_price_imb2',\n",
    " 'far_price_ask_price_wap_imb2',\n",
    " 'far_price_bid_price_wap_imb2',\n",
    " 'near_price_ask_price_bid_price_imb2',\n",
    " 'near_price_ask_price_wap_imb2',\n",
    " 'near_price_bid_price_wap_imb2',\n",
    " 'ask_price_bid_price_wap_imb2',\n",
    " 'pca_prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.torch_classes' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\utils\\\\torch_classes.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(torch_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0', 'gru.weight_ih_l1', 'gru.weight_hh_l1', 'gru.bias_ih_l1', 'gru.bias_hh_l1', 'batch_norm.weight', 'batch_norm.bias', 'batch_norm.running_mean', 'batch_norm.running_var', 'batch_norm.num_batches_tracked', 'layer_norm.weight', 'layer_norm.bias', 'layer_norm2.weight', 'layer_norm2.bias', 'fc0.weight', 'fc0.bias', 'fc1.weight', 'fc1.bias', 'fc_final.weight', 'fc_final.bias', 'fc_reg0.weight', 'fc_reg0.bias', 'fc_reg1.weight', 'fc_reg1.bias', 'fc_reg2.weight', 'fc_reg2.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch_classes.GRUNetV4_sub(89,512,num_layers=2,target_size=15)\n",
    "model_loc = f\"models/expert-blaze-390/expert-blaze-390_20.pt\"\n",
    "model_data = torch.load(model_loc,map_location=torch.device('cpu'))\n",
    "print(model_data['model_state_dict'].keys())\n",
    "model.load_state_dict(model_data['model_state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_feather('train.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(data=list(zip(range(0,201),weights)),columns=['stock_id','index_weight'])\n",
    "train = train.merge(weights_df,on='stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\"\n",
    "median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_data = torch_classes.TradingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "2\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "3\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "4\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "trading_data.fill_hidden_states_for_test(model_data['db_train'])\n",
    "# trading_data.reset_hidden(64,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True)\n",
    "    \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + train['ask_size']\n",
    "#     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "#     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0) \n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "    df['ask_x_size'] = df.eval('ask_size*ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size*bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        \n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        # 'date_id', \n",
    "        'reference_price_far_price_imb',\n",
    "        'reference_price_minus_near_price',\n",
    "        'reference_price_near_price_imb',\n",
    "        'far_price_near_price_imb',\n",
    "        'far_price_ask_price_imb',\n",
    "        'far_price_bid_price_imb',\n",
    "        'far_price_minus_wap',\n",
    "        'std_size',\n",
    "        'bid_size_over_ask_size',\n",
    "        'ask_price_bid_price_imb',\n",
    "        'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prev_race(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'initial_wap'] = df_g['wap_calc'].transform('first')\n",
    "    df[f'initial_bid_size'] = df_g['bid_size'].transform('first')\n",
    "    df[f'initial_ask_size'] = df_g['ask_size'].transform('first')\n",
    "    cols = [\"bid_price\", \"ask_price\", \"bid_size\", \"ask_size\", \"wap\"]\n",
    "    for i in cols:\n",
    "        df[f\"{i}_t10\"] = df_g[i].shift(1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap'] = df_g['wap_weighted'].transform('mean')\n",
    "    return(df)\n",
    "\n",
    "def generate_index_2(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    df[f'index_wap_init'] = df_g['index_wap'].transform('first')\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_eng(train):\n",
    "\n",
    "    train['wap_weighted'] = train['wap']*train['index_weight']\n",
    "    train_g = train.groupby(['stock_id','date_id'])\n",
    "    train = generate_prev_race(train,train_g)\n",
    "\n",
    "    train_g = train.groupby(['seconds_in_bucket','date_id'])\n",
    "    train = generate_index(train,train_g)\n",
    "\n",
    "\n",
    "    train['wap_move_to_init'] = train['wap_calc']/train['initial_wap']\n",
    "    train_g = train.groupby(['date_id'])\n",
    "    train = generate_index_2(train,train_g)\n",
    "\n",
    "    train['index_wap_move_to_init'] = train['index_wap']/train['index_wap_init']\n",
    "    targets = [\"wap\", \"bid_price\", \"ask_price\"]\n",
    "    for i in targets:\n",
    "        train[f\"{i}_prev_move\"] = (train[f\"{i}\"] - train[f\"{i}_t10\"]).fillna(0) * 10000\n",
    "\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reference_price', 'far_price', 'near_price', 'bid_price', 'ask_price', 'bid_price_over_ask_price', 'reference_price_minus_far_price', 'reference_price_times_far_price', 'reference_price_times_near_price', 'reference_price_minus_ask_price', 'reference_price_times_ask_price', 'reference_price_ask_price_imb', 'reference_price_minus_bid_price', 'reference_price_times_bid_price', 'reference_price_bid_price_imb', 'reference_price_minus_wap', 'reference_price_times_wap', 'reference_price_wap_imb', 'far_price_minus_near_price', 'far_price_times_near_price', 'far_price_minus_ask_price', 'far_price_times_ask_price', 'far_price_minus_bid_price', 'far_price_times_bid_price', 'far_price_times_wap', 'far_price_wap_imb', 'near_price_minus_ask_price', 'near_price_times_ask_price', 'near_price_ask_price_imb', 'near_price_minus_bid_price', 'near_price_times_bid_price', 'near_price_bid_price_imb', 'near_price_minus_wap', 'near_price_wap_imb', 'ask_price_minus_bid_price', 'ask_price_times_bid_price', 'ask_price_minus_wap', 'ask_price_times_wap', 'ask_price_wap_imb', 'bid_price_minus_wap', 'bid_price_times_wap', 'bid_price_wap_imb', 'reference_price_far_price_near_price_imb2', 'reference_price_far_price_ask_price_imb2', 'reference_price_far_price_bid_price_imb2', 'reference_price_far_price_wap_imb2', 'reference_price_near_price_ask_price_imb2', 'reference_price_near_price_bid_price_imb2', 'reference_price_near_price_wap_imb2', 'reference_price_ask_price_bid_price_imb2', 'reference_price_ask_price_wap_imb2', 'reference_price_bid_price_wap_imb2', 'far_price_near_price_ask_price_imb2', 'far_price_near_price_bid_price_imb2', 'far_price_near_price_wap_imb2', 'far_price_ask_price_bid_price_imb2', 'far_price_ask_price_wap_imb2', 'far_price_bid_price_wap_imb2', 'near_price_ask_price_bid_price_imb2', 'near_price_ask_price_wap_imb2', 'near_price_bid_price_wap_imb2', 'ask_price_bid_price_wap_imb2']\n"
     ]
    }
   ],
   "source": [
    "y = train[\"target\"].values\n",
    "X = feat_eng(train)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "print(prices)\n",
    "prices = [\n",
    "    c for c in X.columns if (\"price\" in c) and (\"target\" not in c) and (\"60\" not in c)\n",
    "]\n",
    "# prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X[\"pca_prices\"] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.Booster(model_file=\"data/lgbm_model_new_t60.lgb\")\n",
    "# X = train\n",
    "# X_train = X[[c for c in X.columns if (\"target\" not in c) and (\"60\" not in c)]].drop(\n",
    "#     columns=[\"delta_wap\", \"date_id\"]\n",
    "# )\n",
    "# lgbm_preds = lgbm.predict(X_train)\n",
    "# X[\"lgbm_preds\"] = lgbm_preds\n",
    "\n",
    "# del pca_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward_pass(model, new_x, hidden_in):\n",
    "    output_wap_ohe, output_wap, hidden, relu, x_h = model(new_x, hidden_in)\n",
    "    output_wap_ohe = output_wap_ohe.squeeze()\n",
    "    hidden = hidden.transpose(0, 1)\n",
    "    output_wap = output_wap.squeeze()\n",
    "    return output_wap_ohe, output_wap, hidden, x_h , relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_preds(test, trading_data:torch_classes.TradingData, model:torch_classes.GRUNet):\n",
    "    # for col in test.columns:\n",
    "    #     print(col)\n",
    "    test['stats']  = pd.Series(test[stat_col_full].fillna(-1).values.tolist())\n",
    "    stock_ids = test.stock_id.unique().tolist()\n",
    "    stocks = [trading_data.stocksDict[x] for x in stock_ids]\n",
    "    hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1).squeeze()\n",
    "    \n",
    "    X = [torch.tensor(x) for x in test['stats'].tolist()]\n",
    "    \n",
    "    Xstacked = torch.stack(X).unsqueeze(1)\n",
    "\n",
    "    # print(f\"{Xstacked.shape=}\")\n",
    "    # print(f\"{hidden.shape=},{Xstacked.shape=}\")\n",
    "    \n",
    "    \n",
    "    output_wap_ohe, output_wap, hidden, x_h , relu = model_forward_pass(model, Xstacked, hidden)\n",
    "\n",
    "    # print(hidden.shape)\n",
    "    # hidden = hidden.transpose(0,1)\n",
    "    [setattr(obj, \"hidden\", val) for obj, val in zip(stocks, hidden)]\n",
    "    \n",
    "    output = output_wap.flatten().tolist()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "1\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "2\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "3\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "4\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "   Unnamed: 0  stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0     4192980         0      386                  0      2555434.64   \n",
      "1     4192981         1      386                  0       274697.82   \n",
      "2     4192982         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id                                              stats  \n",
      "0  386_0_0  [0.0, 2555434.64, -1.0, 1.000032, 9966697.63, ...  \n",
      "1  386_0_1  [0.0, 274697.82, 1.0, 0.999714, 1324398.6, -1....  \n",
      "2  386_0_2  [0.0, 415532.77, 1.0, 0.999826, 2463160.51, -1...  \n",
      "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0         0      386                  0      2555434.64   \n",
      "1         1      386                  0       274697.82   \n",
      "2         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id  \n",
      "0  386_0_0  \n",
      "1  386_0_1  \n",
      "2  386_0_2  \n",
      "   Unnamed: 0  stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0     4192980         0      386                  0      2555434.64   \n",
      "1     4192981         1      386                  0       274697.82   \n",
      "2     4192982         2      386                  0       415532.77   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                       -1         1.000032    9966697.63        NaN   \n",
      "1                        1         0.999714    1324398.60        NaN   \n",
      "2                        1         0.999826    2463160.51        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target  \\\n",
      "0         NaN   0.999746  18840.60   1.000032   2408.10  1.0 -2.340078   \n",
      "1         NaN   0.999370  71153.73   1.000002    174.08  1.0 -8.130074   \n",
      "2         NaN   0.999323  46315.74   1.000328  22484.74  1.0  0.790358   \n",
      "\n",
      "    row_id                                              stats  \n",
      "0  386_0_0  [0.0, 2555434.64, -1.0, 1.000032, 9966697.63, ...  \n",
      "1  386_0_1  [0.0, 274697.82, 1.0, 0.999714, 1324398.6, -1....  \n",
      "2  386_0_2  [0.0, 415532.77, 1.0, 0.999826, 2463160.51, -1...  \n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n",
      "5000\n",
      "5010\n",
      "5020\n",
      "5030\n",
      "5040\n",
      "5050\n",
      "5060\n",
      "5070\n",
      "5080\n",
      "5090\n",
      "5100\n",
      "5110\n",
      "5120\n",
      "5130\n",
      "5140\n",
      "5150\n",
      "5160\n",
      "5170\n",
      "5180\n",
      "5190\n",
      "5200\n",
      "5210\n",
      "5220\n"
     ]
    }
   ],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "trading_data.fill_hidden_states_for_test(model_data['db_train'])\n",
    "\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    test_in = test[['stock_id','seconds_in_bucket','date_id']].copy()\n",
    "    if counter == 0:\n",
    "        print(test.head(3))\n",
    "        print(revealed_targets.head(3))\n",
    "        print(sample_prediction.head(3))\n",
    "        all_df = test\n",
    "    else:\n",
    "        # all_df = pd.concat([all_df,test])\n",
    "        pass\n",
    "    model = model.eval()\n",
    "    # test = all_df\n",
    "    if counter%10==0:\n",
    "        print(counter)\n",
    "    test['wap_calc'] = (test['bid_price']*test['ask_size']+test['ask_price']*test['bid_size'])/(test['ask_size']+test['bid_size'])\n",
    "    test = test.merge(weights_df,on='stock_id')\n",
    "    test = feat_eng(test)\n",
    "    test['pca_prices'] = pca_prices.transform(test[prices].fillna(1))\n",
    "    if counter ==0:        \n",
    "        test = variable_eng(test)\n",
    "    else:\n",
    "        test = pd.concat([all_df,test])\n",
    "        test = variable_eng(test)\n",
    "    test = test.merge(test_in,on=['stock_id','seconds_in_bucket','date_id'],how='inner')\n",
    "    x = test[[c for c in test.columns if (\"target\" not in c) and (\"60\" not in c)]].drop(columns=[\"date_id\",\"stats\"])\n",
    "    lgbm_preds = lgbm.predict(x[lgbm_columns])\n",
    "    test[\"lgbm_preds\"] = lgbm_preds\n",
    "    \n",
    "    \n",
    "    # print(test.shape)\n",
    "    preditcions = gen_preds(test,trading_data,model)\n",
    "    \n",
    "    sample_prediction['pred'] = preditcions\n",
    "    all_df = test\n",
    "    # print(preditcions)\n",
    "    # break\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in iter_test:\n",
    "    \n",
    "#     test_df = i[0]\n",
    "#     print(test_df)\n",
    "#     test_df['stats']  = pd.Series(test_df[stats_cols].fillna(-1).values.tolist())\n",
    "#     stock_ids = test_df.stock_id.unique()\n",
    "#     stocks = [trading_data.stocksDict[x] for x in stock_ids] \n",
    "#     hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1)\n",
    "#     X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "#     X = torch.stack(X)\n",
    "#     X = pack_sequence(X.view(-1,1,12))\n",
    "\n",
    "    \n",
    "#     model.eval()\n",
    "#     output,hidden = model(X,hidden)\n",
    "#     [setattr(obj, 'hidden', val.detach()) for obj, val in zip(stocks,hidden)]\n",
    "#     print(output)\n",
    "#     test_df['taget'] = output.flatten().tolist()\n",
    "#     # test_df['actual'] = test_df['target']\n",
    "#     env.predict(test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "      <th>stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.5</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0_0_0</td>\n",
       "      <td>[0.0, 3180602.69, 1.0, 0.999812, 13380276.64, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price  ask_size  wap    target row_id  \\\n",
       "0         NaN   0.999812   60651.5   1.000026   8493.03  1.0 -3.029704  0_0_0   \n",
       "\n",
       "                                               stats  \n",
       "0  [0.0, 3180602.69, 1.0, 0.999812, 13380276.64, ...  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8575,  0.7445, -0.8014,  0.7816, -0.5938, -0.7823, -0.7967,\n",
      "          -0.5086,  0.5378, -0.0737, -0.5103, -0.5201, -0.2461, -0.4879,\n",
      "          -0.3435, -0.1746, -0.1386,  0.0818, -0.7184, -0.3409, -0.6650,\n",
      "           0.9997, -0.7376, -0.4719,  0.5599,  0.6262,  0.6931, -0.9579,\n",
      "          -0.6052,  0.0718,  0.6607,  0.6729,  0.0845, -0.4968, -0.6447,\n",
      "          -0.9867,  0.6466, -0.9892, -0.7533,  0.7768, -0.3308, -0.0147,\n",
      "           0.9768,  0.5592,  0.0995, -0.1919,  0.9054,  0.9997, -0.0796,\n",
      "          -0.7784, -0.9714, -0.4716, -0.5839,  0.9843, -0.7999,  0.9457,\n",
      "           0.4040, -1.0000, -0.4622, -0.3323,  0.7707,  0.3389,  0.3091,\n",
      "          -0.8781]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.8575,  0.7445, -0.8015,  0.7816, -0.5938, -0.7823, -0.7968,\n",
      "          -0.5089,  0.5378, -0.0737, -0.5103, -0.5201, -0.2461, -0.4878,\n",
      "          -0.3442, -0.1746, -0.1390,  0.0821, -0.7184, -0.3408, -0.6650,\n",
      "           0.9997, -0.7375, -0.4719,  0.5599,  0.6262,  0.6941, -0.9582,\n",
      "          -0.6053,  0.0717,  0.6607,  0.6729,  0.0846, -0.4968, -0.6447,\n",
      "          -0.9867,  0.6467, -0.9892, -0.7545,  0.7768, -0.3309, -0.0147,\n",
      "           0.9768,  0.5592,  0.0995, -0.1919,  0.9054,  0.9997, -0.0792,\n",
      "          -0.7785, -0.9714, -0.4716, -0.5839,  0.9844, -0.8004,  0.9456,\n",
      "           0.4046, -1.0000, -0.4622, -0.3323,  0.7706,  0.3391,  0.3091,\n",
      "          -0.8787]]], grad_fn=<StackBackward0>)\n",
      "-1.4035744667053223\n",
      "tensor([[[-0.2776,  0.7300,  0.4684,  0.4859, -0.6417, -0.6419, -0.0442,\n",
      "           0.2894,  0.9964, -0.4556, -0.2518, -0.9489, -0.1862,  0.2100,\n",
      "          -0.1263, -0.0886, -0.0576,  1.0000,  0.0706,  0.5752,  0.1624,\n",
      "           0.9595,  0.3823,  0.0916,  0.5848, -0.2474,  0.3140, -0.9481,\n",
      "          -0.6858, -0.0265,  0.7529,  0.6486, -0.3356,  0.2370, -0.9770,\n",
      "          -0.9345,  0.5451, -0.9323, -0.3058,  0.4803, -0.3513,  0.3643,\n",
      "           0.9948,  0.6030,  0.0194, -0.2567,  0.3477,  0.3218, -0.0557,\n",
      "          -0.2221, -0.9273, -0.2433,  0.3337,  0.7029, -0.8221,  0.9600,\n",
      "           0.1987, -1.0000,  0.3080, -0.5119,  0.5234,  0.2743, -0.5009,\n",
      "          -0.7657]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.2776,  0.7300,  0.4684,  0.4859, -0.6417, -0.6418, -0.0444,\n",
      "           0.2895,  0.9964, -0.4556, -0.2519, -0.9489, -0.1863,  0.2100,\n",
      "          -0.1263, -0.0886, -0.0578,  1.0000,  0.0706,  0.5750,  0.1624,\n",
      "           0.9596,  0.3820,  0.0917,  0.5844, -0.2474,  0.3146, -0.9484,\n",
      "          -0.6861, -0.0265,  0.7529,  0.6489, -0.3353,  0.2370, -0.9770,\n",
      "          -0.9346,  0.5452, -0.9324, -0.3060,  0.4800, -0.3512,  0.3643,\n",
      "           0.9948,  0.6030,  0.0194, -0.2567,  0.3478,  0.3225, -0.0557,\n",
      "          -0.2225, -0.9273, -0.2434,  0.3337,  0.7034, -0.8229,  0.9601,\n",
      "           0.1994, -1.0000,  0.3080, -0.5119,  0.5233,  0.2744, -0.5009,\n",
      "          -0.7666]]], grad_fn=<StackBackward0>)\n",
      "-1.020544171333313\n",
      "tensor([[[-3.3288e-01,  7.3953e-01,  2.2678e-01,  6.6525e-01, -5.3614e-01,\n",
      "          -1.7086e-01, -4.8577e-01, -2.2119e-01,  8.7855e-01, -3.6909e-01,\n",
      "          -4.3749e-01, -9.4345e-01, -2.2136e-01,  2.5511e-01,  1.5535e-01,\n",
      "           3.3959e-02, -2.5780e-01,  9.9775e-01, -3.1008e-01, -8.8997e-04,\n",
      "          -3.0357e-01,  9.5762e-01, -7.5892e-01, -2.8284e-01,  4.9396e-01,\n",
      "          -2.3661e-01,  1.9739e-01, -8.6915e-01, -6.8575e-01, -3.7661e-01,\n",
      "           7.8987e-01,  6.3488e-01, -6.9471e-01, -1.1236e-01, -9.5045e-01,\n",
      "          -9.6054e-01,  6.2565e-01, -9.9805e-01, -6.3082e-01, -8.1757e-01,\n",
      "          -1.1894e-01,  5.4986e-01,  9.1603e-01,  4.6996e-01,  1.3606e-01,\n",
      "          -1.9484e-01,  4.1610e-01,  7.9261e-01,  3.9763e-02, -7.0268e-01,\n",
      "          -9.3267e-01, -2.9038e-01, -6.8203e-02,  4.8912e-01, -8.3270e-01,\n",
      "           8.9056e-01,  1.5891e-02, -1.0000e+00, -2.8816e-02,  8.5550e-02,\n",
      "           7.8856e-01,  3.7089e-01, -4.3351e-01, -7.6899e-01]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-3.3292e-01,  7.3953e-01,  2.2671e-01,  6.6525e-01, -5.3614e-01,\n",
      "          -1.7019e-01, -4.8593e-01, -2.2119e-01,  8.7853e-01, -3.6908e-01,\n",
      "          -4.3753e-01, -9.4345e-01, -2.2112e-01,  2.5495e-01,  1.5530e-01,\n",
      "           3.3962e-02, -2.5878e-01,  9.9779e-01, -3.1008e-01, -6.6736e-04,\n",
      "          -3.0362e-01,  9.5766e-01, -7.5894e-01, -2.8285e-01,  4.9331e-01,\n",
      "          -2.3659e-01,  1.9788e-01, -8.6952e-01, -6.8639e-01, -3.7661e-01,\n",
      "           7.8987e-01,  6.3522e-01, -6.9472e-01, -1.1238e-01, -9.5045e-01,\n",
      "          -9.6057e-01,  6.2572e-01, -9.9806e-01, -6.3209e-01, -8.1807e-01,\n",
      "          -1.1857e-01,  5.4987e-01,  9.1603e-01,  4.6996e-01,  1.3608e-01,\n",
      "          -1.9484e-01,  4.1679e-01,  7.9319e-01,  3.9803e-02, -7.0288e-01,\n",
      "          -9.3267e-01, -2.9045e-01, -6.8420e-02,  4.8913e-01, -8.3323e-01,\n",
      "           8.9066e-01,  1.6115e-02, -1.0000e+00, -2.8785e-02,  8.5770e-02,\n",
      "           7.8853e-01,  3.7098e-01, -4.3351e-01, -7.6995e-01]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "-2.2814908027648926\n",
      "tensor([[[-0.7710,  1.0000, -0.2718, -0.2762, -0.9859, -0.9954,  0.9904,\n",
      "          -0.9976,  0.6406, -0.9927, -0.9795, -0.9231, -0.2883, -0.0886,\n",
      "          -0.9993, -0.9989, -0.9985,  0.9992,  0.0962,  0.9905,  0.3119,\n",
      "           0.9669,  0.9974, -0.3228,  0.9932,  0.4761,  0.9908, -0.9905,\n",
      "          -0.9986, -0.2445,  0.2121, -0.9735,  0.7559, -0.6735, -0.0535,\n",
      "          -0.8444, -0.0768,  0.5836,  0.3734,  0.6637, -0.8054,  0.8723,\n",
      "           0.9998,  0.9959, -0.9993, -0.9996, -0.9986, -0.2715, -0.5446,\n",
      "          -0.3907, -0.3915, -0.9997,  0.0719,  0.7859, -0.8440, -0.9910,\n",
      "          -0.9885, -0.9997, -0.7936, -0.9589,  0.8983, -0.8311, -0.7800,\n",
      "           0.6210]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.7711,  1.0000, -0.2740, -0.2763, -0.9860, -0.9954,  0.9904,\n",
      "          -0.9976,  0.6423, -0.9927, -0.9797, -0.9231, -0.2883, -0.0887,\n",
      "          -0.9993, -0.9989, -0.9985,  0.9992,  0.0962,  0.9905,  0.3119,\n",
      "           0.9669,  0.9974, -0.3228,  0.9932,  0.4764,  0.9909, -0.9905,\n",
      "          -0.9986, -0.2445,  0.2120, -0.9735,  0.7578, -0.6735, -0.0537,\n",
      "          -0.8440, -0.0768,  0.5837,  0.3720,  0.6637, -0.8059,  0.8718,\n",
      "           0.9998,  0.9959, -0.9993, -0.9996, -0.9986, -0.2706, -0.5443,\n",
      "          -0.3907, -0.3920, -0.9997,  0.0719,  0.7857, -0.8444, -0.9910,\n",
      "          -0.9885, -0.9997, -0.7937, -0.9589,  0.8984, -0.8315, -0.7800,\n",
      "           0.6228]]], grad_fn=<StackBackward0>)\n",
      "-2.153714656829834\n",
      "tensor([[[-0.3425,  0.8064,  0.0902,  0.5665, -0.4546, -0.1501, -0.5052,\n",
      "          -0.1551,  0.9104, -0.2300, -0.3282, -0.9411, -0.0474,  0.4348,\n",
      "           0.1218,  0.1773, -0.1476,  0.9968, -0.2143,  0.0098, -0.1239,\n",
      "           0.9582, -0.7103, -0.1943,  0.5150, -0.2317,  0.2028, -0.7747,\n",
      "          -0.7960, -0.2437,  0.8126,  0.7476, -0.8604,  0.0579, -0.9651,\n",
      "          -0.9471,  0.6807, -0.9935, -0.7268, -0.8865,  0.0078,  0.5871,\n",
      "           0.8481,  0.6001,  0.2528, -0.0831,  0.3801,  0.7444,  0.1364,\n",
      "          -0.7412, -0.9202, -0.0644, -0.1209,  0.1931, -0.7230,  0.8934,\n",
      "           0.0082, -1.0000,  0.0481, -0.1149,  0.7336,  0.4315, -0.5373,\n",
      "          -0.7494]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.3425,  0.8064,  0.0902,  0.5665, -0.4546, -0.1495, -0.5054,\n",
      "          -0.1551,  0.9104, -0.2300, -0.3282, -0.9411, -0.0469,  0.4348,\n",
      "           0.1218,  0.1773, -0.1482,  0.9969, -0.2143,  0.0101, -0.1239,\n",
      "           0.9582, -0.7105, -0.1943,  0.5145, -0.2317,  0.2031, -0.7743,\n",
      "          -0.7965, -0.2437,  0.8126,  0.7478, -0.8604,  0.0579, -0.9651,\n",
      "          -0.9471,  0.6808, -0.9935, -0.7279, -0.8869,  0.0082,  0.5871,\n",
      "           0.8482,  0.6001,  0.2528, -0.0831,  0.3807,  0.7449,  0.1364,\n",
      "          -0.7413, -0.9202, -0.0645, -0.1212,  0.1929, -0.7237,  0.8935,\n",
      "           0.0083, -1.0000,  0.0482, -0.1147,  0.7336,  0.4316, -0.5373,\n",
      "          -0.7505]]], grad_fn=<StackBackward0>)\n",
      "-3.0033774375915527\n"
     ]
    }
   ],
   "source": [
    "for i,data in test_df.iterrows():\n",
    "    hidden = torch.stack([trading_data.stocksDict[data['stock_id']].hidden])\n",
    "    print(hidden)\n",
    "    hidden = torch.stack([trading_data.stocksDict[data['stock_id']].hidden]).transpose(0,1)\n",
    "    X = torch.tensor(data['stats']).view(-1,12,1)\n",
    "    model.eval()\n",
    "    output,hidden  = model(X,hidden,test=True)\n",
    "    trading_data.stocksDict[data['stock_id']].hidden = hidden[0]\n",
    "    print(hidden)\n",
    "    print(output.flatten().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['stats']  = pd.Series(test_df[stats_cols].fillna(-1).values.tolist())\n",
    "stock_ids = test_df.stock_id.unique()\n",
    "hidden = torch.stack([trading_data.stocksDict[x].hidden for x in stock_ids]).transpose(0,1)\n",
    "X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "# X = pack_sequence(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1240],\n",
       "         [ 1.0552],\n",
       "         [-2.5545],\n",
       "         [ 2.2515],\n",
       "         [-1.9348],\n",
       "         [ 3.7566],\n",
       "         [-0.6949],\n",
       "         [-2.2269],\n",
       "         [-2.6248],\n",
       "         [ 6.1143]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [torch.tensor(x) for x in test_df['stats'].tolist()]\n",
    "X = torch.stack(X).view(-1,12,1)\n",
    "# X = pack_sequence(X)\n",
    "model.eval()\n",
    "output,hidden  = model(X,hidden,test=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1262, -0.1012, -0.2037,  0.1888,  0.0976, -0.2847, -0.5807,\n",
       "          -0.5896, -0.0159,  0.2682, -0.5628,  0.1121, -0.1300,  0.2515,\n",
       "           0.1864,  0.0224,  0.0196, -0.1425, -0.6340, -0.5149, -0.6020,\n",
       "          -0.2689, -0.0297, -0.6029,  0.4218,  0.0321,  0.1283, -0.3335,\n",
       "           0.2974, -0.4182,  0.1575,  0.3770, -0.1936, -0.5595,  0.2087,\n",
       "          -0.1358,  0.1713,  0.1705,  0.0112, -0.2112, -0.5883, -0.2184,\n",
       "           0.6552,  0.0014, -0.0707, -0.0010,  0.4840,  0.5455, -0.3142,\n",
       "          -0.4542, -0.2142, -0.2478, -0.2938, -0.1563, -0.5573,  0.7317,\n",
       "          -0.0501, -0.3461, -0.5378,  0.3539, -0.1586,  0.4133,  0.1239,\n",
       "          -0.1093]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  3.1806e+06,  1.0000e+00,  9.9981e-01,  1.3380e+07,\n",
       "          -1.0000e+00, -1.0000e+00,  9.9981e-01,  6.0652e+04,  1.0000e+00,\n",
       "           8.4930e+03,  1.0000e+00]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(torch_classes)\n",
    "trading_data = torch_classes.TradingData(train)\n",
    "hidden_size = 64\n",
    "# trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(trading_df:torch_classes.TradingData, config:dict):\n",
    "    with wandb.init(project=\"Optviver\", config=config,save_code=True):\n",
    "        wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "        wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "        model = torch_classes.GRUNet(12,hidden_size).to('cuda:0')\n",
    "        config = wandb.config\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        trading_df.reset_hidden(config['hidden_size'])\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        training_testing.train_model(trading_df,model,config,optimizer,criterion)\n",
    "\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {'learning_rate':0.0001, 'hidden_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(trading_data, config_static)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
