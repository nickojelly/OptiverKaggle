{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch_classes\n",
    "from model_saver import model_saver_wandb as model_saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "-0.159740      3477\n",
       "-0.759959      3471\n",
       "-0.050068      3470\n",
       "-0.079870      3467\n",
       " 1.109838      3459\n",
       "               ... \n",
       " 62.299965        1\n",
       " 59.139730        1\n",
       "-70.880060        1\n",
       "-108.349920       1\n",
       "-72.960260        1\n",
       "Name: count, Length: 15934, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = train.target.value_counts(sort=True)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:09<01:32,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=438,for stock_id=19, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [00:48<00:43,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=328,for stock_id=101, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [01:05<01:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=35,for stock_id=131, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [01:23<00:25,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=388,for stock_id=158, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:36<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 385, Length of test 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 1510.26it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 7988.99it/s]\n",
      "c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(torch_classes)\n",
    "trading_data = torch_classes.TradingData(train)\n",
    "hidden_size = 64\n",
    "trading_data.generate_batches()\n",
    "model = torch_classes.GRUNet(12,hidden_size)\n",
    "X = trading_data.packed_x[0]\n",
    "Y = trading_data.packed_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_df = trading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_classes.GRUNet(12,hidden_size).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = [trading_df.stocksDict[x] for x in trading_df.stock_batches[0]]\n",
    "stock_data = trading_df.train_batches\n",
    "X = trading_data.packed_x[0]\n",
    "Y = trading_data.packed_y[0].data\n",
    "\n",
    "hidden_in = torch.stack([x.hidden for x in stocks])\n",
    "\n",
    "output,hidden = model(X)\n",
    "hidden = hidden.transpose(0,1)\n",
    "output  = torch.flatten(output)\n",
    "\n",
    "[setattr(obj, 'hidden', val) for obj, val in zip(stocks,hidden)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = [trading_df.stocksDict[x] for x in trading_df.stock_batches[0]]\n",
    "len(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(31,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([191, 1, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_df.stocksDict[0].hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_df.reset_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_df.stocksDict[0].hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trading_df:torch_classes.TradingData, model:torch_classes.GRUNet, config:dict):\n",
    "    with wandb.init(project=\"Optviver\", config=config,save_code=True):\n",
    "            wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "            wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "            example_ct = 0\n",
    "            epochs = 10000\n",
    "            num_batches = len(trading_df.train_batches)-2\n",
    "            criterion = nn.SmoothL1Loss()\n",
    "            reg_L1 = nn.L1Loss()\n",
    "            model = model.to('cuda:0')\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "            trading_df.reset_hidden(config['hidden_size'])\n",
    "            for epoch in trange(epochs):\n",
    "                model.train()\n",
    "                loss_list = []\n",
    "                \n",
    "                for i in range(0,384):\n",
    "                    # print(i)\n",
    "\n",
    "                    stocks = [trading_df.stocksDict[x] for x in trading_df.stock_batches[i]] #Stocks for the Day\n",
    "                    stock_data = trading_df.train_batches\n",
    "\n",
    "                    example_ct+=1\n",
    "\n",
    "                    X = trading_data.packed_x[i]\n",
    "                    Y = trading_data.packed_y[i].data\n",
    "\n",
    "                    hidden_in = torch.stack([x.hidden for x in stocks]).transpose(0,1)\n",
    "\n",
    "                    output,hidden = model(X,hidden_in)\n",
    "                    hidden = hidden.transpose(0,1)\n",
    "                    output  = torch.flatten(output)\n",
    "\n",
    "                    [setattr(obj, 'hidden', val.detach()) for obj, val in zip(stocks,hidden)]\n",
    "\n",
    "                    if output.shape!=Y.shape:\n",
    "                         print(i,output.shape,Y.shape,)\n",
    "\n",
    "                    loss = criterion(output,Y)\n",
    "                    # print(loss)\n",
    "\n",
    "                    loss.backward()\n",
    "                    loss_list.append((i,loss))\n",
    "                    L1_loss = reg_L1(output,Y)\n",
    "                    if loss.isnan():\n",
    "                         continue\n",
    "                    # print(loss)\n",
    "                    optimizer.step()\n",
    "                    if i == 0:\n",
    "                        epoch_loss = loss\n",
    "                        epoch_reg_l1 = L1_loss\n",
    "                        # print(epoch_loss)\n",
    "                    else:\n",
    "                        if loss.isnan():\n",
    "                            pass\n",
    "                        epoch_loss = loss+epoch_loss\n",
    "                        epoch_reg_l1 = L1_loss+epoch_reg_l1\n",
    "\n",
    "                    wandb.log({\"loss_1\": torch.mean(loss).item()})\n",
    "                    trading_df.detach_hidden()\n",
    "                wandb.log({\"epoch_loss\": epoch_loss/384, \"epoch_l1_loss\": epoch_reg_l1/384, 'epoch':epoch})\n",
    "                validate_model(trading_df,model,criterion,epoch)\n",
    "                if epoch%10==0:\n",
    "                    \n",
    "                    trading_df.create_hidden_states_dict_v2()\n",
    "                    model_saver(model,optimizer,epoch,0,0,trading_df.train_hidden_dict)\n",
    "                    \n",
    "                trading_df.reset_hidden(hidden_size=config['hidden_size'])\n",
    "                # print(epoch_loss)\n",
    "                # print(loss_list)\n",
    "              \n",
    "\n",
    "@torch.no_grad()          \n",
    "def validate_model(trading_df:torch_classes.TradingData,model:torch_classes.GRUNet,criterion,epoch):\n",
    "    model.eval()\n",
    "    val_batches = trading_df.packed_val_x\n",
    "    len_val = len(val_batches)\n",
    "    loss_list = []\n",
    "\n",
    "    # print(len_val)\n",
    "\n",
    "    for i in range(0,len_val-1):\n",
    "        # print(i)\n",
    "        stocks = [trading_df.stocksDict[x] for x in trading_df.val_stock_batches[i]] \n",
    "         \n",
    "        X = trading_df.packed_val_x[i]\n",
    "        Y = trading_df.packed_val_y[i].data\n",
    "\n",
    "        hidden_in = torch.stack([x.hidden for x in stocks]).transpose(0,1)\n",
    "\n",
    "        output,hidden = model(X,hidden_in)\n",
    "        hidden = hidden.transpose(0,1)\n",
    "        output  = torch.flatten(output)\n",
    "\n",
    "        # [setattr(obj, 'hidden', val) for obj, val in zip(stocks,hidden)]\n",
    "\n",
    "        loss = criterion(output,Y)\n",
    "\n",
    "        loss_list.append((i,loss))\n",
    "\n",
    "        # if loss.isnan():\n",
    "        #     continue\n",
    "\n",
    "        # print(f\"{loss=}\")\n",
    "        # print(f\"{i=}\")\n",
    "\n",
    "        if i == 0:\n",
    "            epoch_loss = loss\n",
    "            # print(epoch_loss)\n",
    "        else:\n",
    "            # print(loss)\n",
    "            if loss.isnan():\n",
    "                continue\n",
    "            epoch_loss = loss+epoch_loss\n",
    "    trading_df.reset_hidden(64)\n",
    "    wandb.log({\"val_epoch_loss\": epoch_loss/len_val, 'epoch':epoch})\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_df.detach_hidden()\n",
    "trading_df.reset_hidden(hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {'learning_rate':0.00002, 'hidden_size':64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = len(trading_data.daysDict)\n",
    "len_validation = int(len(trading_data.daysDict)*0.2)\n",
    "len_train = len_data-len_validation\n",
    "val_range = range(len_train+1,len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 96 385 range(386, 481)\n"
     ]
    }
   ],
   "source": [
    "print(len_data,len_validation,len_train,val_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "val_batches = trading_df.packed_val_x\n",
    "len_val = len(val_batches)\n",
    "loss_list = []\n",
    "\n",
    "print(len_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnickojelly\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\wandb\\run-20230930_115702-k5laosfk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/Optviver/runs/k5laosfk' target=\"_blank\">revived-valley-106</a></strong> to <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">https://wandb.ai/nickojelly/Optviver</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/Optviver/runs/k5laosfk' target=\"_blank\">https://wandb.ai/nickojelly/Optviver/runs/k5laosfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87290961e2a042b0aed3b6333cd304ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "train_model(trading_data,model,config=config_static)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
