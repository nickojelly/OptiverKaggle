{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import public_timeseries_testing_util as optiver2023\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, unpack_sequence, unpad_sequence\n",
    "import torch\n",
    "from tqdm.notebook import trange,tqdm\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch_classes\n",
    "import torch_classes_v2\n",
    "from model_saver import model_saver_wandb as model_saver\n",
    "import training_testing\n",
    "from itertools import combinations\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id\n",
       "480    11000\n",
       "353    11000\n",
       "363    11000\n",
       "362    11000\n",
       "360    11000\n",
       "       ...  \n",
       "4      10560\n",
       "2      10505\n",
       "1      10505\n",
       "3      10505\n",
       "0      10505\n",
       "Name: count, Length: 481, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n",
    "train.date_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005000000000000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(weights)/len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame(data=list(zip(range(0,201),weights)),columns=['stock_id','index_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>index_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_id  index_weight\n",
       "0           0         0.004\n",
       "1           1         0.001\n",
       "2           2         0.002\n",
       "3           3         0.006\n",
       "4           4         0.004\n",
       "..        ...           ...\n",
       "195       195         0.004\n",
       "196       196         0.001\n",
       "197       197         0.004\n",
       "198       198         0.006\n",
       "199       199         0.004\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(weights_df,on='stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['wap_calc'] = (train['bid_price']*train['ask_size']+train['ask_price']*train['bid_size'])/(train['ask_size']*train['bid_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'index_weight',\n",
       "       'wap_calc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prev_race(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'wap_t-60'] = df_g['wap'].shift(6)\n",
    "    df[f'target_t-60'] = df_g['target'].shift(6)\n",
    "    df[f'initial_wap'] = df_g['wap_calc'].transform('first')\n",
    "    cols = ['bid_price','ask_price','bid_size','ask_size']\n",
    "    for i in cols:\n",
    "        df[f'{i}_t-60'] = df_g[i].shift(-6)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    # df[f'index_wap_t-60'] = df_g['wap'].shift(6)\n",
    "    # df[f'index_wap'] = df_g['target'].shift(6)\n",
    "    df[f'index_wap'] = df_g['wap_weighted'].transform('mean')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index_2(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'index_wap_t-60'] = df_g['index_wap'].shift(6)\n",
    "    # df[f'index_wap'] = df_g['target'].shift(6)\n",
    "    df[f'index_wap_init'] = df_g['index_wap'].transform('first')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_index_3(df_in, df_g, rolling_window=10, factor=''):\n",
    "    df = df_in.copy()\n",
    "    original_cols = df_in.columns\n",
    "    df[f'index_wap_t-60'] = df_g['index_wap_move_to_init'].shift(6)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index_wap_move_to_init'] = train['index_wap']/train['index_wap_init']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['wap_weighted'] = train['wap']*train['index_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['wap_move_to_init'] = train['wap_calc']/train['initial_wap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = train.groupby(['stock_id','date_id'])\n",
    "train = generate_prev_race(train,train_g)\n",
    "train['delta_wap'] = train['wap']/train['wap_t-60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = train.groupby(['seconds_in_bucket','date_id'])\n",
    "train = generate_index(train,train_g)\n",
    "train['delta_wap'] = (train['wap']/train['wap_t-60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = train.groupby(['date_id'])\n",
    "train = generate_index_2(train,train_g)\n",
    "train['delta_wap'] = (train['wap']/train['wap_t-60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = train.groupby(['date_id'])\n",
    "train = generate_index_3(train,train_g)\n",
    "train['delta_wap'] = (train['wap']/train['wap_t-60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id', 'index_weight',\n",
       "       'wap_calc', 'wap_t-60', 'target_t-60', 'initial_wap', 'bid_price_t-60',\n",
       "       'ask_price_t-60', 'bid_size_t-60', 'ask_size_t-60', 'delta_wap',\n",
       "       'wap_weighted', 'wap_move_to_init', 'index_wap', 'index_wap_t-60',\n",
       "       'index_wap_init', 'index_wap_move_to_init'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target_calc'] = -((train['wap_t-60']/train['wap'])-(train['index_wap_t-60']/train['index_wap_move_to_init']))*10000\n",
    "train['target_delta'] = ((train['target_t-60']-train['target_calc'])/train['target_t-60'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>...</th>\n",
       "      <th>ask_size_t-60</th>\n",
       "      <th>delta_wap</th>\n",
       "      <th>wap_weighted</th>\n",
       "      <th>wap_move_to_init</th>\n",
       "      <th>index_wap</th>\n",
       "      <th>index_wap_t-60</th>\n",
       "      <th>index_wap_init</th>\n",
       "      <th>index_wap_move_to_init</th>\n",
       "      <th>target_calc</th>\n",
       "      <th>target_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>10085.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>17366.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.848928</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>61984.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>2.210527</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1299772.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15261106.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>40433.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.294303</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>42572.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.788523</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>28375.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.930450</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1218204.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>15342674.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>...</td>\n",
       "      <td>68224.23</td>\n",
       "      <td>1.000517</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>1.271280</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000815</td>\n",
       "      <td>-2.979650</td>\n",
       "      <td>1.652109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1264494.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000455</td>\n",
       "      <td>15352380.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>13999.50</td>\n",
       "      <td>1.000529</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.625777</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>1.000356</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>0.420661</td>\n",
       "      <td>-7.913250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1189832.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>15427043.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>25196.40</td>\n",
       "      <td>1.000306</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.910560</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000525</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>4.216233</td>\n",
       "      <td>0.089475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1189272.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>15427602.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>15769.39</td>\n",
       "      <td>1.000341</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.503651</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000547</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000345</td>\n",
       "      <td>5.430774</td>\n",
       "      <td>0.357312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1249282.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000348</td>\n",
       "      <td>15427602.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000241</td>\n",
       "      <td>...</td>\n",
       "      <td>186.58</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.935288</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000264</td>\n",
       "      <td>3.145233</td>\n",
       "      <td>0.774243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>1277280.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15399604.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>28173.58</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.740813</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000668</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>0.573627</td>\n",
       "      <td>4.335395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1216057.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>15460827.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>9330.00</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.280497</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.000815</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000217</td>\n",
       "      <td>-0.235780</td>\n",
       "      <td>-17.729975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>1216057.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>15460827.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>...</td>\n",
       "      <td>21181.37</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>1.000843</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000147</td>\n",
       "      <td>2.368310</td>\n",
       "      <td>1.746649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>1104904.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>15571980.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>59692.80</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.521140</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000129</td>\n",
       "      <td>-0.417175</td>\n",
       "      <td>-7.018945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>74802.54</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.616423</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>1.000345</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>-4.356915</td>\n",
       "      <td>-0.394041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>...</td>\n",
       "      <td>84502.62</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>40.962627</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>1.000264</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>-2.086893</td>\n",
       "      <td>-1.809394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1085679.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>15591206.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>...</td>\n",
       "      <td>9326.00</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.512994</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>-0.012549</td>\n",
       "      <td>161.921444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>1445736.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>15642349.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>...</td>\n",
       "      <td>37320.00</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>1.197369</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>1.000217</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>2.265959</td>\n",
       "      <td>1.050273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1771730.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>15642349.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>...</td>\n",
       "      <td>51304.00</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.750773</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>1.000147</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.980473</td>\n",
       "      <td>1.968964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0          0        0                  0      3180602.69   \n",
       "1          0        0                 10      1299772.70   \n",
       "2          0        0                 20      1299772.70   \n",
       "3          0        0                 30      1299772.70   \n",
       "4          0        0                 40      1218204.43   \n",
       "5          0        0                 50      1218204.43   \n",
       "6          0        0                 60      1218204.43   \n",
       "7          0        0                 70      1264494.89   \n",
       "8          0        0                 80      1189832.86   \n",
       "9          0        0                 90      1189272.89   \n",
       "10         0        0                100      1249282.50   \n",
       "11         0        0                110      1277280.77   \n",
       "12         0        0                120      1216057.90   \n",
       "13         0        0                130      1216057.90   \n",
       "14         0        0                140      1104904.79   \n",
       "15         0        0                150      1085679.32   \n",
       "16         0        0                160      1085679.32   \n",
       "17         0        0                170      1085679.32   \n",
       "18         0        0                180      1445736.98   \n",
       "19         0        0                190      1771730.09   \n",
       "\n",
       "    imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                         1         0.999812   13380276.64        NaN   \n",
       "1                         1         1.000026   15261106.63        NaN   \n",
       "2                         1         0.999919   15261106.63        NaN   \n",
       "3                         1         1.000133   15261106.63        NaN   \n",
       "4                         1         1.000455   15342674.90        NaN   \n",
       "5                         1         1.000455   15342674.90        NaN   \n",
       "6                         1         1.000562   15342674.90        NaN   \n",
       "7                         1         1.000455   15352380.96        NaN   \n",
       "8                         1         1.000241   15427043.00        NaN   \n",
       "9                         1         1.000562   15427602.97        NaN   \n",
       "10                        1         1.000348   15427602.97        NaN   \n",
       "11                        1         1.000133   15399604.70        NaN   \n",
       "12                        1         1.000133   15460827.57        NaN   \n",
       "13                        1         1.000026   15460827.57        NaN   \n",
       "14                        1         0.999919   15571980.68        NaN   \n",
       "15                        1         0.999812   15591206.15        NaN   \n",
       "16                        1         0.999598   15591206.15        NaN   \n",
       "17                        1         0.999598   15591206.15        NaN   \n",
       "18                        1         0.999705   15642349.64        NaN   \n",
       "19                        1         0.999812   15642349.64        NaN   \n",
       "\n",
       "    near_price  bid_price  ...  ask_size_t-60  delta_wap  wap_weighted  \\\n",
       "0          NaN   0.999812  ...       10085.04        NaN      0.004000   \n",
       "1          NaN   0.999812  ...       17366.82        NaN      0.004000   \n",
       "2          NaN   0.999812  ...       61984.40        NaN      0.003999   \n",
       "3          NaN   1.000026  ...       40433.54        NaN      0.004000   \n",
       "4          NaN   1.000241  ...       42572.16        NaN      0.004001   \n",
       "5          NaN   1.000348  ...       28375.36        NaN      0.004002   \n",
       "6          NaN   1.000455  ...       68224.23   1.000517      0.004002   \n",
       "7          NaN   1.000348  ...       13999.50   1.000529      0.004002   \n",
       "8          NaN   1.000133  ...       25196.40   1.000306      0.004001   \n",
       "9          NaN   1.000348  ...       15769.39   1.000341      0.004002   \n",
       "10         NaN   1.000241  ...         186.58   0.999944      0.004001   \n",
       "11         NaN   1.000026  ...       28173.58   0.999608      0.004000   \n",
       "12         NaN   0.999812  ...        9330.00   0.999378      0.004000   \n",
       "13         NaN   0.999812  ...       21181.37   0.999541      0.004000   \n",
       "14         NaN   0.999705  ...       59692.80   0.999678      0.003999   \n",
       "15         NaN   0.999705  ...       74802.54   0.999361      0.003999   \n",
       "16         NaN   0.999491  ...       84502.62   0.999334      0.003998   \n",
       "17         NaN   0.999383  ...        9326.00   0.999452      0.003998   \n",
       "18         NaN   0.999598  ...       37320.00   0.999774      0.003999   \n",
       "19         NaN   0.999705  ...       51304.00   0.999793      0.003999   \n",
       "\n",
       "    wap_move_to_init  index_wap  index_wap_t-60 index_wap_init  \\\n",
       "0           1.000000   0.005031             NaN       0.005031   \n",
       "1           0.848928   0.005033             NaN       0.005031   \n",
       "2           2.210527   0.005034             NaN       0.005031   \n",
       "3           0.294303   0.005034             NaN       0.005031   \n",
       "4           0.788523   0.005035             NaN       0.005031   \n",
       "5           0.930450   0.005035             NaN       0.005031   \n",
       "6           1.271280   0.005036        1.000000       0.005031   \n",
       "7           0.625777   0.005036        1.000356       0.005031   \n",
       "8           0.910560   0.005033        1.000525       0.005031   \n",
       "9           0.503651   0.005033        1.000547       0.005031   \n",
       "10          0.935288   0.005033        1.000635       0.005031   \n",
       "11          1.740813   0.005033        1.000668       0.005031   \n",
       "12          0.280497   0.005033        1.000815       0.005031   \n",
       "13          0.760234   0.005032        1.000843       0.005031   \n",
       "14          0.521140   0.005032        1.000409       0.005031   \n",
       "15          0.616423   0.005032        1.000345       0.005031   \n",
       "16         40.962627   0.005030        1.000264       0.005031   \n",
       "17          0.512994   0.005030        1.000218       0.005031   \n",
       "18          1.197369   0.005030        1.000217       0.005031   \n",
       "19          0.750773   0.005031        1.000147       0.005031   \n",
       "\n",
       "    index_wap_move_to_init  target_calc  target_delta  \n",
       "0                 1.000000          NaN           NaN  \n",
       "1                 1.000356          NaN           NaN  \n",
       "2                 1.000525          NaN           NaN  \n",
       "3                 1.000547          NaN           NaN  \n",
       "4                 1.000635          NaN           NaN  \n",
       "5                 1.000668          NaN           NaN  \n",
       "6                 1.000815    -2.979650      1.652109  \n",
       "7                 1.000843     0.420661     -7.913250  \n",
       "8                 1.000409     4.216233      0.089475  \n",
       "9                 1.000345     5.430774      0.357312  \n",
       "10                1.000264     3.145233      0.774243  \n",
       "11                1.000218     0.573627      4.335395  \n",
       "12                1.000217    -0.235780    -17.729975  \n",
       "13                1.000147     2.368310      1.746649  \n",
       "14                1.000129    -0.417175     -7.018945  \n",
       "15                1.000142    -4.356915     -0.394041  \n",
       "16                0.999807    -2.086893     -1.809394  \n",
       "17                0.999672    -0.012549    161.921444  \n",
       "18                0.999764     2.265959      1.050273  \n",
       "19                0.999842     0.980473      1.968964  \n",
       "\n",
       "[20 rows x 35 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stock_0 = train[train['stock_id']==0]\n",
    "train_stock_0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_with_new_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol = pd.read_csv(\"archive/MedianVolV2.csv\")\n",
    "median_vol.index.name = \"stock_id\"\n",
    "median_vol = median_vol[['overall_medvol', \"first5min_medvol\", \"last5min_medvol\"]]\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df = df.merge(median_vol, how = \"left\", left_on = \"stock_id\", right_index = True)\n",
    "    \n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + train['ask_size']\n",
    "#     df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "#     df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0) \n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "\n",
    "    df['ask_x_size'] = df.eval('ask_size*ask_price')\n",
    "    df['bid_x_size'] = df.eval('bid_size*bid_price')\n",
    "        \n",
    "    df['ask_minus_bid'] = df['ask_x_size'] - df['bid_x_size'] \n",
    "    \n",
    "    df[\"bid_size_over_ask_size\"] = df[\"bid_size\"].div(df[\"ask_size\"])\n",
    "    df[\"bid_price_over_ask_price\"] = df[\"bid_price\"].div(df[\"ask_price\"])\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for c in combinations(prices, 2):\n",
    "        \n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_times_{c[1]}'] = (df[f'{c[0]}'] * df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]}-{c[1]})/({c[0]}+{c[1]})')\n",
    "\n",
    "    for c in combinations(prices, 3):\n",
    "        \n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1)-min_-max_\n",
    "\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "    \n",
    "        \n",
    "    df.drop(columns=[\n",
    "        # 'date_id', \n",
    "        'reference_price_far_price_imb',\n",
    "        'reference_price_minus_near_price',\n",
    "        'reference_price_near_price_imb',\n",
    "        'far_price_near_price_imb',\n",
    "        'far_price_ask_price_imb',\n",
    "        'far_price_bid_price_imb',\n",
    "        'far_price_minus_wap',\n",
    "        'std_size',\n",
    "        'bid_size_over_ask_size',\n",
    "        'ask_price_bid_price_imb',\n",
    "        'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target'].values\n",
    "X = feat_eng(train)\n",
    "prices = [c for c in train.columns if 'price' in c]\n",
    "pca_prices = PCA(n_components=1)\n",
    "X['pca_prices'] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.Booster(model_file='lgbm_model.lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_columns = ['stock_id', 'seconds_in_bucket', 'imbalance_size',\n",
    "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
    "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
    "       'ask_size', 'wap', 'overall_medvol', 'first5min_medvol',\n",
    "       'last5min_medvol', 'bid_plus_ask_sizes', 'imbalance_ratio', 'imb_s1',\n",
    "       'imb_s2', 'ask_x_size', 'bid_x_size', 'ask_minus_bid',\n",
    "       'bid_price_over_ask_price', 'reference_price_minus_far_price',\n",
    "       'reference_price_times_far_price', 'reference_price_times_near_price',\n",
    "       'reference_price_minus_ask_price', 'reference_price_times_ask_price',\n",
    "       'reference_price_ask_price_imb', 'reference_price_minus_bid_price',\n",
    "       'reference_price_times_bid_price', 'reference_price_bid_price_imb',\n",
    "       'reference_price_minus_wap', 'reference_price_times_wap',\n",
    "       'reference_price_wap_imb', 'far_price_minus_near_price',\n",
    "       'far_price_times_near_price', 'far_price_minus_ask_price',\n",
    "       'far_price_times_ask_price', 'far_price_minus_bid_price',\n",
    "       'far_price_times_bid_price', 'far_price_times_wap', 'far_price_wap_imb',\n",
    "       'near_price_minus_ask_price', 'near_price_times_ask_price',\n",
    "       'near_price_ask_price_imb', 'near_price_minus_bid_price',\n",
    "       'near_price_times_bid_price', 'near_price_bid_price_imb',\n",
    "       'near_price_minus_wap', 'near_price_wap_imb',\n",
    "       'ask_price_minus_bid_price', 'ask_price_times_bid_price',\n",
    "       'ask_price_minus_wap', 'ask_price_times_wap', 'ask_price_wap_imb',\n",
    "       'bid_price_minus_wap', 'bid_price_times_wap', 'bid_price_wap_imb',\n",
    "       'reference_price_far_price_near_price_imb2',\n",
    "       'reference_price_far_price_ask_price_imb2',\n",
    "       'reference_price_far_price_bid_price_imb2',\n",
    "       'reference_price_far_price_wap_imb2',\n",
    "       'reference_price_near_price_ask_price_imb2',\n",
    "       'reference_price_near_price_bid_price_imb2',\n",
    "       'reference_price_near_price_wap_imb2',\n",
    "       'reference_price_ask_price_bid_price_imb2',\n",
    "       'reference_price_ask_price_wap_imb2',\n",
    "       'reference_price_bid_price_wap_imb2',\n",
    "       'far_price_near_price_ask_price_imb2',\n",
    "       'far_price_near_price_bid_price_imb2', 'far_price_near_price_wap_imb2',\n",
    "       'far_price_ask_price_bid_price_imb2', 'far_price_ask_price_wap_imb2',\n",
    "       'far_price_bid_price_wap_imb2', 'near_price_ask_price_bid_price_imb2',\n",
    "       'near_price_ask_price_wap_imb2', 'near_price_bid_price_wap_imb2',\n",
    "       'ask_price_bid_price_wap_imb2', 'pca_prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_preds = lgbm.predict(X[lgbm_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['lgbm_preds'] = lgbm_preds\n",
    "lgbm_preds =  []\n",
    "del lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:12<02:43,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=438,for stock_id=19, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [00:54<00:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=328,for stock_id=101, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [01:17<00:34,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=35,for stock_id=131, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [01:33<00:21,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Targets for day=388,for stock_id=158, Excluding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:05<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 385, Length of test 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 8662.52it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 9952.02it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(torch_classes)\n",
    "trading_data = torch_classes.TradingData(X)\n",
    "hidden_size = 64\n",
    "trading_data.generate_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trading_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.2.2.6.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m stock \u001b[39min\u001b[39;00m trading_data\u001b[39m.\u001b[39mstocksDict\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     stock\u001b[39m.\u001b[39mdata_daily \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trading_data' is not defined"
     ]
    }
   ],
   "source": [
    "for stock in trading_data.stocksDict.values():\n",
    "    stock.data_daily = []\n",
    "\n",
    "train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(torch_classes)\n",
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_dict = {\n",
    "    'RMSProp':optim.RMSprop,\n",
    "    \"Adam\":optim.Adam,\n",
    "    \"AdamW\":optim.AdamW,\n",
    "    'SGD':optim.SGD,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(trading_df=trading_data, config=None):\n",
    "    trading_df = trading_data\n",
    "    with wandb.init(project=\"Optviver\", config=config,save_code=True):\n",
    "        wandb.define_metric(\"val_epoch_loss_l1\", summary=\"min\")\n",
    "        wandb.define_metric(\"epoch_l1_loss\", summary=\"min\")\n",
    "        config = wandb.config\n",
    "        \n",
    "        model = torch_classes.GRUNetV2(19,config['hidden_size'],num_layers=config['num_layers']).to('cuda:0')\n",
    "        config = wandb.config\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
    "        print(model)\n",
    "        trading_df.reset_hidden(hidden_size=config['hidden_size'],num_layers=config['num_layers'])\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        \n",
    "        training_testing.train_model(trading_df,model,config,optimizer,criterion)\n",
    "\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_testing' from 'c:\\\\Users\\\\Nick\\\\Documents\\\\GitHub\\\\OptiverKaggle\\\\training_testing.py'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(training_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_data.reset_hidden(16,num_layers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [trading_data.stocksDict[x] for x in trading_data.stock_batches[0]] \n",
    "hidden_in = torch.stack([x.hidden for x in stocks]).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 191, 16])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_static = {'learning_rate':0.001, 'hidden_size':16, 'num_layers':2, 'batch_norm':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\wandb\\run-20231127_150047-qhgrxlyn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nickojelly/Optviver/runs/qhgrxlyn' target=\"_blank\">solar-deluge-328</a></strong> to <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nickojelly/Optviver' target=\"_blank\">https://wandb.ai/nickojelly/Optviver</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nickojelly/Optviver/runs/qhgrxlyn' target=\"_blank\">https://wandb.ai/nickojelly/Optviver/runs/qhgrxlyn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNetV2(\n",
      "  (gru): GRU(19, 16, num_layers=2, dropout=0.3)\n",
      "  (relu0): ReLU()\n",
      "  (batch_norm): BatchNorm1d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc0): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (rl1): ReLU()\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (rl2): ReLU()\n",
      "  (drop2): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (rl3): ReLU()\n",
      "  (drop3): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16cd5a54c6542c2822b5bfae56b90a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_24316\\318259873.py\", line 15, in model_pipeline\n",
      "    training_testing.train_model(trading_df,model,config,optimizer,criterion)\n",
      "  File \"c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\training_testing.py\", line 38, in train_model\n",
      "    output,hidden = model(X,hidden_in)\n",
      "                    ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\torch_classes.py\", line 230, in forward\n",
      "    x = self.fc0(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c6c23760494cf1becc06c0668e83d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.037 MB of 0.037 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_l1_loss</td><td>▇▃▂▂▁▃▄▆████████████████████████████████</td></tr><tr><td>epoch_loss</td><td>▇▃▂▂▁▃▄▆████████████████████████████████</td></tr><tr><td>loss_1</td><td>█████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃█</td></tr><tr><td>val_epoch_loss</td><td>▁▃▁▁▂▅▃▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_epoch_loss_l1</td><td>▁▃▁▁▂▅▃▇▇▇▇▇▇▇██████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>epoch_loss</td><td>6.01286</td></tr><tr><td>loss_1</td><td>5.1003</td></tr><tr><td>val_epoch_loss</td><td>5.5349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-deluge-328</strong> at: <a href='https://wandb.ai/nickojelly/Optviver/runs/qhgrxlyn' target=\"_blank\">https://wandb.ai/nickojelly/Optviver/runs/qhgrxlyn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231127_150047-qhgrxlyn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.2.2.6.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#Y243sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model_pipeline(trading_data, config_static)\n",
      "\u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\Optiver_v0.2.2.6.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#Y243sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     trading_df\u001b[39m.\u001b[39mreset_hidden(hidden_size\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m'\u001b[39m],num_layers\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mnum_layers\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#Y243sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSmoothL1Loss()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#Y243sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     training_testing\u001b[39m.\u001b[39;49mtrain_model(trading_df,model,config,optimizer,criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nick/Documents/GitHub/OptiverKaggle/Optiver_v0.2.2.6.ipynb#Y243sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(model)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\training_testing.py:38\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(trading_df, model, config, optimizer, criterion)\u001b[0m\n\u001b[0;32m     34\u001b[0m Y \u001b[39m=\u001b[39m trading_df\u001b[39m.\u001b[39mpacked_y[i]\u001b[39m.\u001b[39mdata\n\u001b[0;32m     36\u001b[0m hidden_in \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([x\u001b[39m.\u001b[39mhidden \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m stocks])\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m output,hidden \u001b[39m=\u001b[39m model(X,hidden_in)\n\u001b[0;32m     39\u001b[0m hidden \u001b[39m=\u001b[39m hidden\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m output  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(output)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Nick\\Documents\\GitHub\\OptiverKaggle\\torch_classes.py:230\u001b[0m, in \u001b[0;36mGRUNetV2.forward\u001b[1;34m(self, x, h, test)\u001b[0m\n\u001b[0;32m    228\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu0(x)\n\u001b[0;32m    229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop1(x)\n\u001b[1;32m--> 230\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc0(x)\n\u001b[0;32m    231\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrl1(x)\n\u001b[0;32m    232\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop1(x)\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Nick\\.conda\\envs\\python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_pipeline(trading_data, config_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch_classes.GRUNetV2(81,config['hidden_size'],num_layers=config['num_layers'], batch_norm=config['batch_norm']).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden,targets = trading_data.fetch_daily_data(day=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden,targets = trading_data.fetch_daily_data(day=1)\n",
    "\n",
    "stocks_hidden = [torch.stack(x) for x in stocks_hidden]\n",
    "\n",
    "X = torch.cat(stocks_hidden,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_hidden = []\n",
    "stock_targets = []\n",
    "\n",
    "for i in range(0,200):\n",
    "    # print(i)\n",
    "    \n",
    "    try:\n",
    "        stock_lgbm = trading_data.stocksDict[i].lgbm_pred_daily[1]\n",
    "        stock_targets.append(torch.stack(trading_data.stocksDict[i].target_daily[1]))\n",
    "    except KeyError as e:\n",
    "        stock_targets.append(torch.zeros(55,device='cuda:0'))\n",
    "        \n",
    "\n",
    "    stock_hidden.append([torch.cat((x,y.reshape(1)),0) for x,y in zip(trading_data.stocksDict[i].hidden_all,stock_lgbm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden_og = stocks_hidden\n",
    "X1 = torch.cat(stocks_hidden_og,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden_og?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden_og[0] == stocks_hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_hidden = []\n",
    "stock_targets = []\n",
    "\n",
    "for i in range(0,200):\n",
    "    # print(i)\n",
    "    \n",
    "    try:\n",
    "        stock_lgbm = trading_data.stocksDict[i].lgbm_pred_daily[1]\n",
    "        stock_targets.append(torch.stack(trading_data.stocksDict[i].target_daily[1]))\n",
    "    except KeyError as e:\n",
    "        stock_targets.append(torch.zeros(55,device='cuda:0'))\n",
    "        \n",
    "\n",
    "    stock_hidden.append([torch.cat((x,y.reshape(1)),0) for x,y in zip(trading_data.stocksDict[i].hidden_all,stock_lgbm)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_hidden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_hidden = []\n",
    "stock_targets = []\n",
    "\n",
    "for i in range(0,200):\n",
    "    # print(i)\n",
    "    \n",
    "    try:\n",
    "        stock_lgbm = torch.stack(trading_data.stocksDict[i].lgbm_pred_daily[1]).reshape(-1,1)\n",
    "        stock_targets.append(torch.stack(trading_data.stocksDict[i].target_daily[1]))\n",
    "    except KeyError as e:\n",
    "        stock_targets.append(torch.zeros(55,device='cuda:0'))\n",
    "        \n",
    "    # print(stock_lgbm.shape)\n",
    "    # print(trading_data.stocksDict[i].hidden_all.shape)\n",
    "    stock_hidden.append([torch.cat((trading_data.stocksDict[i].hidden_all,stock_lgbm),dim=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden_og = stocks_hidden\n",
    "X1 = torch.cat(stocks_hidden_og,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_lgbm = torch.stack(trading_data.stocksDict[1].lgbm_pred_daily[1])\n",
    "stock_lgbm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = trading_data.stocksDict[1].hidden_all\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([hidden,stock_lgbm],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stock_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_hidden = [torch.stack(x) for x in stocks_hidden]\n",
    "X = torch.cat(stocks_hidden,dim=-1)\n",
    "Y = torch.stack(targets).transpose(0,1).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, relu = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\"method\": \"random\"}\n",
    "\n",
    "metric = {\"name\": \"val_epoch_loss\", \"goal\": \"minimize\"}\n",
    "\n",
    "sweep_config[\"metric\"] = metric\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    \"optimizer\": {\"values\": [\"adamW\", 'adam', 'SGD', 'RMSprop']},\n",
    "    \"f0_layer_size\": {\"values\": [128]},\n",
    "    \"f1_layer_size\": {\"values\": [64]},\n",
    "    \"num_layers\": {\"values\": [2,3,4,5]},\n",
    "    'hidden_size':{'values':[8,16,32,64,128,256,512,1024]},\n",
    "    'learning_rate': {'max': 0.001, 'min': 0.00001},\n",
    "    'batch_norm':{'values':[0,1,2]}\n",
    "}\n",
    "\n",
    "sweep_config[\"parameters\"] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Optiver Sweeps\")\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "wandb.agent(sweep_id, function=model_pipeline, count=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
