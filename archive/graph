digraph {
	graph [size="19.95,19.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2293064596272 [label="
 ()" fillcolor=darkolivegreen1]
	2293388201888 [label=MeanBackward0]
	2293388201696 -> 2293388201888
	2293388201696 [label=SqueezeBackward0]
	2293388201600 -> 2293388201696
	2293388201600 [label=ViewBackward0]
	2293388201216 -> 2293388201600
	2293388201216 [label=AddmmBackward0]
	2293388199488 -> 2293388201216
	2293380299856 [label="fc_final.bias
 (5)" fillcolor=lightblue]
	2293380299856 -> 2293388199488
	2293388199488 [label=AccumulateGrad]
	2293388200928 -> 2293388201216
	2293388200928 [label=ViewBackward0]
	2293388200736 -> 2293388200928
	2293388200736 [label=NativeDropoutBackward0]
	2293388200256 -> 2293388200736
	2293388200256 [label=ReluBackward0]
	2293388199104 -> 2293388200256
	2293388199104 [label=NativeLayerNormBackward0]
	2293388199680 -> 2293388199104
	2293388199680 [label=ViewBackward0]
	2293388199008 -> 2293388199680
	2293388199008 [label=AddmmBackward0]
	2293388200448 -> 2293388199008
	2293380299472 [label="fc1.bias
 (256)" fillcolor=lightblue]
	2293380299472 -> 2293388200448
	2293388200448 [label=AccumulateGrad]
	2293388199296 -> 2293388199008
	2293388199296 [label=ViewBackward0]
	2293388198528 -> 2293388199296
	2293388198528 [label=NativeDropoutBackward0]
	2293388202752 -> 2293388198528
	2293388202752 [label=ReluBackward0]
	2293388202848 -> 2293388202752
	2293388202848 [label=NativeLayerNormBackward0]
	2293388203040 -> 2293388202848
	2293388203040 [label=CudnnRnnBackward0]
	2293388203424 -> 2293388203040
	2293388203424 [label=ReluBackward0]
	2293388204384 -> 2293388203424
	2293388204384 [label=AddBackward0]
	2293388204576 -> 2293388204384
	2293388204576 [label=UnsafeViewBackward0]
	2293388204864 -> 2293388204576
	2293388204864 [label=MmBackward0]
	2293388205056 -> 2293388204864
	2293388205056 [label=UnsafeViewBackward0]
	2293388205344 -> 2293388205056
	2293388205344 [label=CloneBackward0]
	2293388205536 -> 2293388205344
	2293388205536 [label=TransposeBackward0]
	2293388205728 -> 2293388205536
	2293388205728 [label=CudnnBatchNormBackward0]
	2293388205920 -> 2293388205728
	2293380299280 [label="batch_norm.weight
 (22)" fillcolor=lightblue]
	2293380299280 -> 2293388205920
	2293388205920 [label=AccumulateGrad]
	2293388205824 -> 2293388205728
	2293380298224 [label="batch_norm.bias
 (22)" fillcolor=lightblue]
	2293380298224 -> 2293388205824
	2293388205824 [label=AccumulateGrad]
	2293388204960 -> 2293388204864
	2293388204960 [label=TBackward0]
	2293388205632 -> 2293388204960
	2293380297456 [label="fc0.weight
 (256, 22)" fillcolor=lightblue]
	2293380297456 -> 2293388205632
	2293388205632 [label=AccumulateGrad]
	2293388204480 -> 2293388204384
	2293380297360 [label="fc0.bias
 (256)" fillcolor=lightblue]
	2293380297360 -> 2293388204480
	2293388204480 [label=AccumulateGrad]
	2293388203328 -> 2293388203040
	2293380298992 [label="gru.weight_ih_l0
 (768, 256)" fillcolor=lightblue]
	2293380298992 -> 2293388203328
	2293388203328 [label=AccumulateGrad]
	2293388203232 -> 2293388203040
	2293380298896 [label="gru.weight_hh_l0
 (768, 256)" fillcolor=lightblue]
	2293380298896 -> 2293388203232
	2293388203232 [label=AccumulateGrad]
	2293388203520 -> 2293388203040
	2293380298800 [label="gru.bias_ih_l0
 (768)" fillcolor=lightblue]
	2293380298800 -> 2293388203520
	2293388203520 [label=AccumulateGrad]
	2293388203616 -> 2293388203040
	2293380298704 [label="gru.bias_hh_l0
 (768)" fillcolor=lightblue]
	2293380298704 -> 2293388203616
	2293388203616 [label=AccumulateGrad]
	2293388203712 -> 2293388203040
	2293380298608 [label="gru.weight_ih_l1
 (768, 256)" fillcolor=lightblue]
	2293380298608 -> 2293388203712
	2293388203712 [label=AccumulateGrad]
	2293388203808 -> 2293388203040
	2293380298512 [label="gru.weight_hh_l1
 (768, 256)" fillcolor=lightblue]
	2293380298512 -> 2293388203808
	2293388203808 [label=AccumulateGrad]
	2293388203904 -> 2293388203040
	2293380298416 [label="gru.bias_ih_l1
 (768)" fillcolor=lightblue]
	2293380298416 -> 2293388203904
	2293388203904 [label=AccumulateGrad]
	2293388204000 -> 2293388203040
	2293380298320 [label="gru.bias_hh_l1
 (768)" fillcolor=lightblue]
	2293380298320 -> 2293388204000
	2293388204000 [label=AccumulateGrad]
	2293388202944 -> 2293388202848
	2293380297840 [label="layer_norm.weight
 (256)" fillcolor=lightblue]
	2293380297840 -> 2293388202944
	2293388202944 [label=AccumulateGrad]
	2293388202560 -> 2293388202848
	2293380297744 [label="layer_norm.bias
 (256)" fillcolor=lightblue]
	2293380297744 -> 2293388202560
	2293388202560 [label=AccumulateGrad]
	2293388199584 -> 2293388199008
	2293388199584 [label=TBackward0]
	2293388202656 -> 2293388199584
	2293380297264 [label="fc1.weight
 (256, 256)" fillcolor=lightblue]
	2293380297264 -> 2293388202656
	2293388202656 [label=AccumulateGrad]
	2293388199776 -> 2293388199104
	2293380297648 [label="layer_norm2.weight
 (256)" fillcolor=lightblue]
	2293380297648 -> 2293388199776
	2293388199776 [label=AccumulateGrad]
	2293388200640 -> 2293388199104
	2293380297552 [label="layer_norm2.bias
 (256)" fillcolor=lightblue]
	2293380297552 -> 2293388200640
	2293388200640 [label=AccumulateGrad]
	2293388202272 -> 2293388201216
	2293388202272 [label=TBackward0]
	2293388199872 -> 2293388202272
	2293380299760 [label="fc_final.weight
 (5, 256)" fillcolor=lightblue]
	2293380299760 -> 2293388199872
	2293388199872 [label=AccumulateGrad]
	2293388201888 -> 2293064596272
}
